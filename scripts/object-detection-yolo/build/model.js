/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
(function webpackUniversalModuleDefinition(root, factory) {
	if(typeof exports === 'object' && typeof module === 'object')
		module.exports = factory();
	else if(typeof define === 'function' && define.amd)
		define([], factory);
	else {
		var a = factory();
		for(var i in a) (typeof exports === 'object' ? exports : root)[i] = a[i];
	}
})(global, function() {
return /******/ (() => { // webpackBootstrap
/******/ 	var __webpack_modules__ = ({

/***/ "./node_modules/_fs-extra@8.1.0@fs-extra/lib/copy-sync/copy-sync.js":
/*!**************************************************************************!*\
  !*** ./node_modules/_fs-extra@8.1.0@fs-extra/lib/copy-sync/copy-sync.js ***!
  \**************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/_graceful-fs@4.2.8@graceful-fs/graceful-fs.js\")\nconst path = __webpack_require__(/*! path */ \"path\")\nconst mkdirpSync = __webpack_require__(/*! ../mkdirs */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/mkdirs/index.js\").mkdirsSync\nconst utimesSync = __webpack_require__(/*! ../util/utimes.js */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/util/utimes.js\").utimesMillisSync\nconst stat = __webpack_require__(/*! ../util/stat */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/util/stat.js\")\n\nfunction copySync (src, dest, opts) {\n  if (typeof opts === 'function') {\n    opts = { filter: opts }\n  }\n\n  opts = opts || {}\n  opts.clobber = 'clobber' in opts ? !!opts.clobber : true // default to true for now\n  opts.overwrite = 'overwrite' in opts ? !!opts.overwrite : opts.clobber // overwrite falls back to clobber\n\n  // Warn about using preserveTimestamps on 32-bit node\n  if (opts.preserveTimestamps && process.arch === 'ia32') {\n    console.warn(`fs-extra: Using the preserveTimestamps option in 32-bit node is not recommended;\\n\n    see https://github.com/jprichardson/node-fs-extra/issues/269`)\n  }\n\n  const { srcStat, destStat } = stat.checkPathsSync(src, dest, 'copy')\n  stat.checkParentPathsSync(src, srcStat, dest, 'copy')\n  return handleFilterAndCopy(destStat, src, dest, opts)\n}\n\nfunction handleFilterAndCopy (destStat, src, dest, opts) {\n  if (opts.filter && !opts.filter(src, dest)) return\n  const destParent = path.dirname(dest)\n  if (!fs.existsSync(destParent)) mkdirpSync(destParent)\n  return startCopy(destStat, src, dest, opts)\n}\n\nfunction startCopy (destStat, src, dest, opts) {\n  if (opts.filter && !opts.filter(src, dest)) return\n  return getStats(destStat, src, dest, opts)\n}\n\nfunction getStats (destStat, src, dest, opts) {\n  const statSync = opts.dereference ? fs.statSync : fs.lstatSync\n  const srcStat = statSync(src)\n\n  if (srcStat.isDirectory()) return onDir(srcStat, destStat, src, dest, opts)\n  else if (srcStat.isFile() ||\n           srcStat.isCharacterDevice() ||\n           srcStat.isBlockDevice()) return onFile(srcStat, destStat, src, dest, opts)\n  else if (srcStat.isSymbolicLink()) return onLink(destStat, src, dest, opts)\n}\n\nfunction onFile (srcStat, destStat, src, dest, opts) {\n  if (!destStat) return copyFile(srcStat, src, dest, opts)\n  return mayCopyFile(srcStat, src, dest, opts)\n}\n\nfunction mayCopyFile (srcStat, src, dest, opts) {\n  if (opts.overwrite) {\n    fs.unlinkSync(dest)\n    return copyFile(srcStat, src, dest, opts)\n  } else if (opts.errorOnExist) {\n    throw new Error(`'${dest}' already exists`)\n  }\n}\n\nfunction copyFile (srcStat, src, dest, opts) {\n  if (typeof fs.copyFileSync === 'function') {\n    fs.copyFileSync(src, dest)\n    fs.chmodSync(dest, srcStat.mode)\n    if (opts.preserveTimestamps) {\n      return utimesSync(dest, srcStat.atime, srcStat.mtime)\n    }\n    return\n  }\n  return copyFileFallback(srcStat, src, dest, opts)\n}\n\nfunction copyFileFallback (srcStat, src, dest, opts) {\n  const BUF_LENGTH = 64 * 1024\n  const _buff = __webpack_require__(/*! ../util/buffer */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/util/buffer.js\")(BUF_LENGTH)\n\n  const fdr = fs.openSync(src, 'r')\n  const fdw = fs.openSync(dest, 'w', srcStat.mode)\n  let pos = 0\n\n  while (pos < srcStat.size) {\n    const bytesRead = fs.readSync(fdr, _buff, 0, BUF_LENGTH, pos)\n    fs.writeSync(fdw, _buff, 0, bytesRead)\n    pos += bytesRead\n  }\n\n  if (opts.preserveTimestamps) fs.futimesSync(fdw, srcStat.atime, srcStat.mtime)\n\n  fs.closeSync(fdr)\n  fs.closeSync(fdw)\n}\n\nfunction onDir (srcStat, destStat, src, dest, opts) {\n  if (!destStat) return mkDirAndCopy(srcStat, src, dest, opts)\n  if (destStat && !destStat.isDirectory()) {\n    throw new Error(`Cannot overwrite non-directory '${dest}' with directory '${src}'.`)\n  }\n  return copyDir(src, dest, opts)\n}\n\nfunction mkDirAndCopy (srcStat, src, dest, opts) {\n  fs.mkdirSync(dest)\n  copyDir(src, dest, opts)\n  return fs.chmodSync(dest, srcStat.mode)\n}\n\nfunction copyDir (src, dest, opts) {\n  fs.readdirSync(src).forEach(item => copyDirItem(item, src, dest, opts))\n}\n\nfunction copyDirItem (item, src, dest, opts) {\n  const srcItem = path.join(src, item)\n  const destItem = path.join(dest, item)\n  const { destStat } = stat.checkPathsSync(srcItem, destItem, 'copy')\n  return startCopy(destStat, srcItem, destItem, opts)\n}\n\nfunction onLink (destStat, src, dest, opts) {\n  let resolvedSrc = fs.readlinkSync(src)\n  if (opts.dereference) {\n    resolvedSrc = path.resolve(process.cwd(), resolvedSrc)\n  }\n\n  if (!destStat) {\n    return fs.symlinkSync(resolvedSrc, dest)\n  } else {\n    let resolvedDest\n    try {\n      resolvedDest = fs.readlinkSync(dest)\n    } catch (err) {\n      // dest exists and is a regular file or directory,\n      // Windows may throw UNKNOWN error. If dest already exists,\n      // fs throws error anyway, so no need to guard against it here.\n      if (err.code === 'EINVAL' || err.code === 'UNKNOWN') return fs.symlinkSync(resolvedSrc, dest)\n      throw err\n    }\n    if (opts.dereference) {\n      resolvedDest = path.resolve(process.cwd(), resolvedDest)\n    }\n    if (stat.isSrcSubdir(resolvedSrc, resolvedDest)) {\n      throw new Error(`Cannot copy '${resolvedSrc}' to a subdirectory of itself, '${resolvedDest}'.`)\n    }\n\n    // prevent copy if src is a subdir of dest since unlinking\n    // dest in this case would result in removing src contents\n    // and therefore a broken symlink would be created.\n    if (fs.statSync(dest).isDirectory() && stat.isSrcSubdir(resolvedDest, resolvedSrc)) {\n      throw new Error(`Cannot overwrite '${resolvedDest}' with '${resolvedSrc}'.`)\n    }\n    return copyLink(resolvedSrc, dest)\n  }\n}\n\nfunction copyLink (resolvedSrc, dest) {\n  fs.unlinkSync(dest)\n  return fs.symlinkSync(resolvedSrc, dest)\n}\n\nmodule.exports = copySync\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_fs-extra@8.1.0@fs-extra/lib/copy-sync/copy-sync.js?");

/***/ }),

/***/ "./node_modules/_fs-extra@8.1.0@fs-extra/lib/copy-sync/index.js":
/*!**********************************************************************!*\
  !*** ./node_modules/_fs-extra@8.1.0@fs-extra/lib/copy-sync/index.js ***!
  \**********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nmodule.exports = {\n  copySync: __webpack_require__(/*! ./copy-sync */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/copy-sync/copy-sync.js\")\n}\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_fs-extra@8.1.0@fs-extra/lib/copy-sync/index.js?");

/***/ }),

/***/ "./node_modules/_fs-extra@8.1.0@fs-extra/lib/copy/copy.js":
/*!****************************************************************!*\
  !*** ./node_modules/_fs-extra@8.1.0@fs-extra/lib/copy/copy.js ***!
  \****************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/_graceful-fs@4.2.8@graceful-fs/graceful-fs.js\")\nconst path = __webpack_require__(/*! path */ \"path\")\nconst mkdirp = __webpack_require__(/*! ../mkdirs */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/mkdirs/index.js\").mkdirs\nconst pathExists = __webpack_require__(/*! ../path-exists */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/path-exists/index.js\").pathExists\nconst utimes = __webpack_require__(/*! ../util/utimes */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/util/utimes.js\").utimesMillis\nconst stat = __webpack_require__(/*! ../util/stat */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/util/stat.js\")\n\nfunction copy (src, dest, opts, cb) {\n  if (typeof opts === 'function' && !cb) {\n    cb = opts\n    opts = {}\n  } else if (typeof opts === 'function') {\n    opts = { filter: opts }\n  }\n\n  cb = cb || function () {}\n  opts = opts || {}\n\n  opts.clobber = 'clobber' in opts ? !!opts.clobber : true // default to true for now\n  opts.overwrite = 'overwrite' in opts ? !!opts.overwrite : opts.clobber // overwrite falls back to clobber\n\n  // Warn about using preserveTimestamps on 32-bit node\n  if (opts.preserveTimestamps && process.arch === 'ia32') {\n    console.warn(`fs-extra: Using the preserveTimestamps option in 32-bit node is not recommended;\\n\n    see https://github.com/jprichardson/node-fs-extra/issues/269`)\n  }\n\n  stat.checkPaths(src, dest, 'copy', (err, stats) => {\n    if (err) return cb(err)\n    const { srcStat, destStat } = stats\n    stat.checkParentPaths(src, srcStat, dest, 'copy', err => {\n      if (err) return cb(err)\n      if (opts.filter) return handleFilter(checkParentDir, destStat, src, dest, opts, cb)\n      return checkParentDir(destStat, src, dest, opts, cb)\n    })\n  })\n}\n\nfunction checkParentDir (destStat, src, dest, opts, cb) {\n  const destParent = path.dirname(dest)\n  pathExists(destParent, (err, dirExists) => {\n    if (err) return cb(err)\n    if (dirExists) return startCopy(destStat, src, dest, opts, cb)\n    mkdirp(destParent, err => {\n      if (err) return cb(err)\n      return startCopy(destStat, src, dest, opts, cb)\n    })\n  })\n}\n\nfunction handleFilter (onInclude, destStat, src, dest, opts, cb) {\n  Promise.resolve(opts.filter(src, dest)).then(include => {\n    if (include) return onInclude(destStat, src, dest, opts, cb)\n    return cb()\n  }, error => cb(error))\n}\n\nfunction startCopy (destStat, src, dest, opts, cb) {\n  if (opts.filter) return handleFilter(getStats, destStat, src, dest, opts, cb)\n  return getStats(destStat, src, dest, opts, cb)\n}\n\nfunction getStats (destStat, src, dest, opts, cb) {\n  const stat = opts.dereference ? fs.stat : fs.lstat\n  stat(src, (err, srcStat) => {\n    if (err) return cb(err)\n\n    if (srcStat.isDirectory()) return onDir(srcStat, destStat, src, dest, opts, cb)\n    else if (srcStat.isFile() ||\n             srcStat.isCharacterDevice() ||\n             srcStat.isBlockDevice()) return onFile(srcStat, destStat, src, dest, opts, cb)\n    else if (srcStat.isSymbolicLink()) return onLink(destStat, src, dest, opts, cb)\n  })\n}\n\nfunction onFile (srcStat, destStat, src, dest, opts, cb) {\n  if (!destStat) return copyFile(srcStat, src, dest, opts, cb)\n  return mayCopyFile(srcStat, src, dest, opts, cb)\n}\n\nfunction mayCopyFile (srcStat, src, dest, opts, cb) {\n  if (opts.overwrite) {\n    fs.unlink(dest, err => {\n      if (err) return cb(err)\n      return copyFile(srcStat, src, dest, opts, cb)\n    })\n  } else if (opts.errorOnExist) {\n    return cb(new Error(`'${dest}' already exists`))\n  } else return cb()\n}\n\nfunction copyFile (srcStat, src, dest, opts, cb) {\n  if (typeof fs.copyFile === 'function') {\n    return fs.copyFile(src, dest, err => {\n      if (err) return cb(err)\n      return setDestModeAndTimestamps(srcStat, dest, opts, cb)\n    })\n  }\n  return copyFileFallback(srcStat, src, dest, opts, cb)\n}\n\nfunction copyFileFallback (srcStat, src, dest, opts, cb) {\n  const rs = fs.createReadStream(src)\n  rs.on('error', err => cb(err)).once('open', () => {\n    const ws = fs.createWriteStream(dest, { mode: srcStat.mode })\n    ws.on('error', err => cb(err))\n      .on('open', () => rs.pipe(ws))\n      .once('close', () => setDestModeAndTimestamps(srcStat, dest, opts, cb))\n  })\n}\n\nfunction setDestModeAndTimestamps (srcStat, dest, opts, cb) {\n  fs.chmod(dest, srcStat.mode, err => {\n    if (err) return cb(err)\n    if (opts.preserveTimestamps) {\n      return utimes(dest, srcStat.atime, srcStat.mtime, cb)\n    }\n    return cb()\n  })\n}\n\nfunction onDir (srcStat, destStat, src, dest, opts, cb) {\n  if (!destStat) return mkDirAndCopy(srcStat, src, dest, opts, cb)\n  if (destStat && !destStat.isDirectory()) {\n    return cb(new Error(`Cannot overwrite non-directory '${dest}' with directory '${src}'.`))\n  }\n  return copyDir(src, dest, opts, cb)\n}\n\nfunction mkDirAndCopy (srcStat, src, dest, opts, cb) {\n  fs.mkdir(dest, err => {\n    if (err) return cb(err)\n    copyDir(src, dest, opts, err => {\n      if (err) return cb(err)\n      return fs.chmod(dest, srcStat.mode, cb)\n    })\n  })\n}\n\nfunction copyDir (src, dest, opts, cb) {\n  fs.readdir(src, (err, items) => {\n    if (err) return cb(err)\n    return copyDirItems(items, src, dest, opts, cb)\n  })\n}\n\nfunction copyDirItems (items, src, dest, opts, cb) {\n  const item = items.pop()\n  if (!item) return cb()\n  return copyDirItem(items, item, src, dest, opts, cb)\n}\n\nfunction copyDirItem (items, item, src, dest, opts, cb) {\n  const srcItem = path.join(src, item)\n  const destItem = path.join(dest, item)\n  stat.checkPaths(srcItem, destItem, 'copy', (err, stats) => {\n    if (err) return cb(err)\n    const { destStat } = stats\n    startCopy(destStat, srcItem, destItem, opts, err => {\n      if (err) return cb(err)\n      return copyDirItems(items, src, dest, opts, cb)\n    })\n  })\n}\n\nfunction onLink (destStat, src, dest, opts, cb) {\n  fs.readlink(src, (err, resolvedSrc) => {\n    if (err) return cb(err)\n    if (opts.dereference) {\n      resolvedSrc = path.resolve(process.cwd(), resolvedSrc)\n    }\n\n    if (!destStat) {\n      return fs.symlink(resolvedSrc, dest, cb)\n    } else {\n      fs.readlink(dest, (err, resolvedDest) => {\n        if (err) {\n          // dest exists and is a regular file or directory,\n          // Windows may throw UNKNOWN error. If dest already exists,\n          // fs throws error anyway, so no need to guard against it here.\n          if (err.code === 'EINVAL' || err.code === 'UNKNOWN') return fs.symlink(resolvedSrc, dest, cb)\n          return cb(err)\n        }\n        if (opts.dereference) {\n          resolvedDest = path.resolve(process.cwd(), resolvedDest)\n        }\n        if (stat.isSrcSubdir(resolvedSrc, resolvedDest)) {\n          return cb(new Error(`Cannot copy '${resolvedSrc}' to a subdirectory of itself, '${resolvedDest}'.`))\n        }\n\n        // do not copy if src is a subdir of dest since unlinking\n        // dest in this case would result in removing src contents\n        // and therefore a broken symlink would be created.\n        if (destStat.isDirectory() && stat.isSrcSubdir(resolvedDest, resolvedSrc)) {\n          return cb(new Error(`Cannot overwrite '${resolvedDest}' with '${resolvedSrc}'.`))\n        }\n        return copyLink(resolvedSrc, dest, cb)\n      })\n    }\n  })\n}\n\nfunction copyLink (resolvedSrc, dest, cb) {\n  fs.unlink(dest, err => {\n    if (err) return cb(err)\n    return fs.symlink(resolvedSrc, dest, cb)\n  })\n}\n\nmodule.exports = copy\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_fs-extra@8.1.0@fs-extra/lib/copy/copy.js?");

/***/ }),

/***/ "./node_modules/_fs-extra@8.1.0@fs-extra/lib/copy/index.js":
/*!*****************************************************************!*\
  !*** ./node_modules/_fs-extra@8.1.0@fs-extra/lib/copy/index.js ***!
  \*****************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst u = __webpack_require__(/*! universalify */ \"./node_modules/_universalify@0.1.2@universalify/index.js\").fromCallback\nmodule.exports = {\n  copy: u(__webpack_require__(/*! ./copy */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/copy/copy.js\"))\n}\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_fs-extra@8.1.0@fs-extra/lib/copy/index.js?");

/***/ }),

/***/ "./node_modules/_fs-extra@8.1.0@fs-extra/lib/empty/index.js":
/*!******************************************************************!*\
  !*** ./node_modules/_fs-extra@8.1.0@fs-extra/lib/empty/index.js ***!
  \******************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst u = __webpack_require__(/*! universalify */ \"./node_modules/_universalify@0.1.2@universalify/index.js\").fromCallback\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/_graceful-fs@4.2.8@graceful-fs/graceful-fs.js\")\nconst path = __webpack_require__(/*! path */ \"path\")\nconst mkdir = __webpack_require__(/*! ../mkdirs */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/mkdirs/index.js\")\nconst remove = __webpack_require__(/*! ../remove */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/remove/index.js\")\n\nconst emptyDir = u(function emptyDir (dir, callback) {\n  callback = callback || function () {}\n  fs.readdir(dir, (err, items) => {\n    if (err) return mkdir.mkdirs(dir, callback)\n\n    items = items.map(item => path.join(dir, item))\n\n    deleteItem()\n\n    function deleteItem () {\n      const item = items.pop()\n      if (!item) return callback()\n      remove.remove(item, err => {\n        if (err) return callback(err)\n        deleteItem()\n      })\n    }\n  })\n})\n\nfunction emptyDirSync (dir) {\n  let items\n  try {\n    items = fs.readdirSync(dir)\n  } catch (err) {\n    return mkdir.mkdirsSync(dir)\n  }\n\n  items.forEach(item => {\n    item = path.join(dir, item)\n    remove.removeSync(item)\n  })\n}\n\nmodule.exports = {\n  emptyDirSync,\n  emptydirSync: emptyDirSync,\n  emptyDir,\n  emptydir: emptyDir\n}\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_fs-extra@8.1.0@fs-extra/lib/empty/index.js?");

/***/ }),

/***/ "./node_modules/_fs-extra@8.1.0@fs-extra/lib/ensure/file.js":
/*!******************************************************************!*\
  !*** ./node_modules/_fs-extra@8.1.0@fs-extra/lib/ensure/file.js ***!
  \******************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst u = __webpack_require__(/*! universalify */ \"./node_modules/_universalify@0.1.2@universalify/index.js\").fromCallback\nconst path = __webpack_require__(/*! path */ \"path\")\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/_graceful-fs@4.2.8@graceful-fs/graceful-fs.js\")\nconst mkdir = __webpack_require__(/*! ../mkdirs */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/mkdirs/index.js\")\nconst pathExists = __webpack_require__(/*! ../path-exists */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/path-exists/index.js\").pathExists\n\nfunction createFile (file, callback) {\n  function makeFile () {\n    fs.writeFile(file, '', err => {\n      if (err) return callback(err)\n      callback()\n    })\n  }\n\n  fs.stat(file, (err, stats) => { // eslint-disable-line handle-callback-err\n    if (!err && stats.isFile()) return callback()\n    const dir = path.dirname(file)\n    pathExists(dir, (err, dirExists) => {\n      if (err) return callback(err)\n      if (dirExists) return makeFile()\n      mkdir.mkdirs(dir, err => {\n        if (err) return callback(err)\n        makeFile()\n      })\n    })\n  })\n}\n\nfunction createFileSync (file) {\n  let stats\n  try {\n    stats = fs.statSync(file)\n  } catch (e) {}\n  if (stats && stats.isFile()) return\n\n  const dir = path.dirname(file)\n  if (!fs.existsSync(dir)) {\n    mkdir.mkdirsSync(dir)\n  }\n\n  fs.writeFileSync(file, '')\n}\n\nmodule.exports = {\n  createFile: u(createFile),\n  createFileSync\n}\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_fs-extra@8.1.0@fs-extra/lib/ensure/file.js?");

/***/ }),

/***/ "./node_modules/_fs-extra@8.1.0@fs-extra/lib/ensure/index.js":
/*!*******************************************************************!*\
  !*** ./node_modules/_fs-extra@8.1.0@fs-extra/lib/ensure/index.js ***!
  \*******************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst file = __webpack_require__(/*! ./file */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/ensure/file.js\")\nconst link = __webpack_require__(/*! ./link */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/ensure/link.js\")\nconst symlink = __webpack_require__(/*! ./symlink */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/ensure/symlink.js\")\n\nmodule.exports = {\n  // file\n  createFile: file.createFile,\n  createFileSync: file.createFileSync,\n  ensureFile: file.createFile,\n  ensureFileSync: file.createFileSync,\n  // link\n  createLink: link.createLink,\n  createLinkSync: link.createLinkSync,\n  ensureLink: link.createLink,\n  ensureLinkSync: link.createLinkSync,\n  // symlink\n  createSymlink: symlink.createSymlink,\n  createSymlinkSync: symlink.createSymlinkSync,\n  ensureSymlink: symlink.createSymlink,\n  ensureSymlinkSync: symlink.createSymlinkSync\n}\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_fs-extra@8.1.0@fs-extra/lib/ensure/index.js?");

/***/ }),

/***/ "./node_modules/_fs-extra@8.1.0@fs-extra/lib/ensure/link.js":
/*!******************************************************************!*\
  !*** ./node_modules/_fs-extra@8.1.0@fs-extra/lib/ensure/link.js ***!
  \******************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst u = __webpack_require__(/*! universalify */ \"./node_modules/_universalify@0.1.2@universalify/index.js\").fromCallback\nconst path = __webpack_require__(/*! path */ \"path\")\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/_graceful-fs@4.2.8@graceful-fs/graceful-fs.js\")\nconst mkdir = __webpack_require__(/*! ../mkdirs */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/mkdirs/index.js\")\nconst pathExists = __webpack_require__(/*! ../path-exists */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/path-exists/index.js\").pathExists\n\nfunction createLink (srcpath, dstpath, callback) {\n  function makeLink (srcpath, dstpath) {\n    fs.link(srcpath, dstpath, err => {\n      if (err) return callback(err)\n      callback(null)\n    })\n  }\n\n  pathExists(dstpath, (err, destinationExists) => {\n    if (err) return callback(err)\n    if (destinationExists) return callback(null)\n    fs.lstat(srcpath, (err) => {\n      if (err) {\n        err.message = err.message.replace('lstat', 'ensureLink')\n        return callback(err)\n      }\n\n      const dir = path.dirname(dstpath)\n      pathExists(dir, (err, dirExists) => {\n        if (err) return callback(err)\n        if (dirExists) return makeLink(srcpath, dstpath)\n        mkdir.mkdirs(dir, err => {\n          if (err) return callback(err)\n          makeLink(srcpath, dstpath)\n        })\n      })\n    })\n  })\n}\n\nfunction createLinkSync (srcpath, dstpath) {\n  const destinationExists = fs.existsSync(dstpath)\n  if (destinationExists) return undefined\n\n  try {\n    fs.lstatSync(srcpath)\n  } catch (err) {\n    err.message = err.message.replace('lstat', 'ensureLink')\n    throw err\n  }\n\n  const dir = path.dirname(dstpath)\n  const dirExists = fs.existsSync(dir)\n  if (dirExists) return fs.linkSync(srcpath, dstpath)\n  mkdir.mkdirsSync(dir)\n\n  return fs.linkSync(srcpath, dstpath)\n}\n\nmodule.exports = {\n  createLink: u(createLink),\n  createLinkSync\n}\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_fs-extra@8.1.0@fs-extra/lib/ensure/link.js?");

/***/ }),

/***/ "./node_modules/_fs-extra@8.1.0@fs-extra/lib/ensure/symlink-paths.js":
/*!***************************************************************************!*\
  !*** ./node_modules/_fs-extra@8.1.0@fs-extra/lib/ensure/symlink-paths.js ***!
  \***************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst path = __webpack_require__(/*! path */ \"path\")\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/_graceful-fs@4.2.8@graceful-fs/graceful-fs.js\")\nconst pathExists = __webpack_require__(/*! ../path-exists */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/path-exists/index.js\").pathExists\n\n/**\n * Function that returns two types of paths, one relative to symlink, and one\n * relative to the current working directory. Checks if path is absolute or\n * relative. If the path is relative, this function checks if the path is\n * relative to symlink or relative to current working directory. This is an\n * initiative to find a smarter `srcpath` to supply when building symlinks.\n * This allows you to determine which path to use out of one of three possible\n * types of source paths. The first is an absolute path. This is detected by\n * `path.isAbsolute()`. When an absolute path is provided, it is checked to\n * see if it exists. If it does it's used, if not an error is returned\n * (callback)/ thrown (sync). The other two options for `srcpath` are a\n * relative url. By default Node's `fs.symlink` works by creating a symlink\n * using `dstpath` and expects the `srcpath` to be relative to the newly\n * created symlink. If you provide a `srcpath` that does not exist on the file\n * system it results in a broken symlink. To minimize this, the function\n * checks to see if the 'relative to symlink' source file exists, and if it\n * does it will use it. If it does not, it checks if there's a file that\n * exists that is relative to the current working directory, if does its used.\n * This preserves the expectations of the original fs.symlink spec and adds\n * the ability to pass in `relative to current working direcotry` paths.\n */\n\nfunction symlinkPaths (srcpath, dstpath, callback) {\n  if (path.isAbsolute(srcpath)) {\n    return fs.lstat(srcpath, (err) => {\n      if (err) {\n        err.message = err.message.replace('lstat', 'ensureSymlink')\n        return callback(err)\n      }\n      return callback(null, {\n        'toCwd': srcpath,\n        'toDst': srcpath\n      })\n    })\n  } else {\n    const dstdir = path.dirname(dstpath)\n    const relativeToDst = path.join(dstdir, srcpath)\n    return pathExists(relativeToDst, (err, exists) => {\n      if (err) return callback(err)\n      if (exists) {\n        return callback(null, {\n          'toCwd': relativeToDst,\n          'toDst': srcpath\n        })\n      } else {\n        return fs.lstat(srcpath, (err) => {\n          if (err) {\n            err.message = err.message.replace('lstat', 'ensureSymlink')\n            return callback(err)\n          }\n          return callback(null, {\n            'toCwd': srcpath,\n            'toDst': path.relative(dstdir, srcpath)\n          })\n        })\n      }\n    })\n  }\n}\n\nfunction symlinkPathsSync (srcpath, dstpath) {\n  let exists\n  if (path.isAbsolute(srcpath)) {\n    exists = fs.existsSync(srcpath)\n    if (!exists) throw new Error('absolute srcpath does not exist')\n    return {\n      'toCwd': srcpath,\n      'toDst': srcpath\n    }\n  } else {\n    const dstdir = path.dirname(dstpath)\n    const relativeToDst = path.join(dstdir, srcpath)\n    exists = fs.existsSync(relativeToDst)\n    if (exists) {\n      return {\n        'toCwd': relativeToDst,\n        'toDst': srcpath\n      }\n    } else {\n      exists = fs.existsSync(srcpath)\n      if (!exists) throw new Error('relative srcpath does not exist')\n      return {\n        'toCwd': srcpath,\n        'toDst': path.relative(dstdir, srcpath)\n      }\n    }\n  }\n}\n\nmodule.exports = {\n  symlinkPaths,\n  symlinkPathsSync\n}\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_fs-extra@8.1.0@fs-extra/lib/ensure/symlink-paths.js?");

/***/ }),

/***/ "./node_modules/_fs-extra@8.1.0@fs-extra/lib/ensure/symlink-type.js":
/*!**************************************************************************!*\
  !*** ./node_modules/_fs-extra@8.1.0@fs-extra/lib/ensure/symlink-type.js ***!
  \**************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/_graceful-fs@4.2.8@graceful-fs/graceful-fs.js\")\n\nfunction symlinkType (srcpath, type, callback) {\n  callback = (typeof type === 'function') ? type : callback\n  type = (typeof type === 'function') ? false : type\n  if (type) return callback(null, type)\n  fs.lstat(srcpath, (err, stats) => {\n    if (err) return callback(null, 'file')\n    type = (stats && stats.isDirectory()) ? 'dir' : 'file'\n    callback(null, type)\n  })\n}\n\nfunction symlinkTypeSync (srcpath, type) {\n  let stats\n\n  if (type) return type\n  try {\n    stats = fs.lstatSync(srcpath)\n  } catch (e) {\n    return 'file'\n  }\n  return (stats && stats.isDirectory()) ? 'dir' : 'file'\n}\n\nmodule.exports = {\n  symlinkType,\n  symlinkTypeSync\n}\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_fs-extra@8.1.0@fs-extra/lib/ensure/symlink-type.js?");

/***/ }),

/***/ "./node_modules/_fs-extra@8.1.0@fs-extra/lib/ensure/symlink.js":
/*!*********************************************************************!*\
  !*** ./node_modules/_fs-extra@8.1.0@fs-extra/lib/ensure/symlink.js ***!
  \*********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst u = __webpack_require__(/*! universalify */ \"./node_modules/_universalify@0.1.2@universalify/index.js\").fromCallback\nconst path = __webpack_require__(/*! path */ \"path\")\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/_graceful-fs@4.2.8@graceful-fs/graceful-fs.js\")\nconst _mkdirs = __webpack_require__(/*! ../mkdirs */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/mkdirs/index.js\")\nconst mkdirs = _mkdirs.mkdirs\nconst mkdirsSync = _mkdirs.mkdirsSync\n\nconst _symlinkPaths = __webpack_require__(/*! ./symlink-paths */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/ensure/symlink-paths.js\")\nconst symlinkPaths = _symlinkPaths.symlinkPaths\nconst symlinkPathsSync = _symlinkPaths.symlinkPathsSync\n\nconst _symlinkType = __webpack_require__(/*! ./symlink-type */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/ensure/symlink-type.js\")\nconst symlinkType = _symlinkType.symlinkType\nconst symlinkTypeSync = _symlinkType.symlinkTypeSync\n\nconst pathExists = __webpack_require__(/*! ../path-exists */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/path-exists/index.js\").pathExists\n\nfunction createSymlink (srcpath, dstpath, type, callback) {\n  callback = (typeof type === 'function') ? type : callback\n  type = (typeof type === 'function') ? false : type\n\n  pathExists(dstpath, (err, destinationExists) => {\n    if (err) return callback(err)\n    if (destinationExists) return callback(null)\n    symlinkPaths(srcpath, dstpath, (err, relative) => {\n      if (err) return callback(err)\n      srcpath = relative.toDst\n      symlinkType(relative.toCwd, type, (err, type) => {\n        if (err) return callback(err)\n        const dir = path.dirname(dstpath)\n        pathExists(dir, (err, dirExists) => {\n          if (err) return callback(err)\n          if (dirExists) return fs.symlink(srcpath, dstpath, type, callback)\n          mkdirs(dir, err => {\n            if (err) return callback(err)\n            fs.symlink(srcpath, dstpath, type, callback)\n          })\n        })\n      })\n    })\n  })\n}\n\nfunction createSymlinkSync (srcpath, dstpath, type) {\n  const destinationExists = fs.existsSync(dstpath)\n  if (destinationExists) return undefined\n\n  const relative = symlinkPathsSync(srcpath, dstpath)\n  srcpath = relative.toDst\n  type = symlinkTypeSync(relative.toCwd, type)\n  const dir = path.dirname(dstpath)\n  const exists = fs.existsSync(dir)\n  if (exists) return fs.symlinkSync(srcpath, dstpath, type)\n  mkdirsSync(dir)\n  return fs.symlinkSync(srcpath, dstpath, type)\n}\n\nmodule.exports = {\n  createSymlink: u(createSymlink),\n  createSymlinkSync\n}\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_fs-extra@8.1.0@fs-extra/lib/ensure/symlink.js?");

/***/ }),

/***/ "./node_modules/_fs-extra@8.1.0@fs-extra/lib/fs/index.js":
/*!***************************************************************!*\
  !*** ./node_modules/_fs-extra@8.1.0@fs-extra/lib/fs/index.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// This is adapted from https://github.com/normalize/mz\n// Copyright (c) 2014-2016 Jonathan Ong me@jongleberry.com and Contributors\nconst u = __webpack_require__(/*! universalify */ \"./node_modules/_universalify@0.1.2@universalify/index.js\").fromCallback\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/_graceful-fs@4.2.8@graceful-fs/graceful-fs.js\")\n\nconst api = [\n  'access',\n  'appendFile',\n  'chmod',\n  'chown',\n  'close',\n  'copyFile',\n  'fchmod',\n  'fchown',\n  'fdatasync',\n  'fstat',\n  'fsync',\n  'ftruncate',\n  'futimes',\n  'lchown',\n  'lchmod',\n  'link',\n  'lstat',\n  'mkdir',\n  'mkdtemp',\n  'open',\n  'readFile',\n  'readdir',\n  'readlink',\n  'realpath',\n  'rename',\n  'rmdir',\n  'stat',\n  'symlink',\n  'truncate',\n  'unlink',\n  'utimes',\n  'writeFile'\n].filter(key => {\n  // Some commands are not available on some systems. Ex:\n  // fs.copyFile was added in Node.js v8.5.0\n  // fs.mkdtemp was added in Node.js v5.10.0\n  // fs.lchown is not available on at least some Linux\n  return typeof fs[key] === 'function'\n})\n\n// Export all keys:\nObject.keys(fs).forEach(key => {\n  if (key === 'promises') {\n    // fs.promises is a getter property that triggers ExperimentalWarning\n    // Don't re-export it here, the getter is defined in \"lib/index.js\"\n    return\n  }\n  exports[key] = fs[key]\n})\n\n// Universalify async methods:\napi.forEach(method => {\n  exports[method] = u(fs[method])\n})\n\n// We differ from mz/fs in that we still ship the old, broken, fs.exists()\n// since we are a drop-in replacement for the native module\nexports.exists = function (filename, callback) {\n  if (typeof callback === 'function') {\n    return fs.exists(filename, callback)\n  }\n  return new Promise(resolve => {\n    return fs.exists(filename, resolve)\n  })\n}\n\n// fs.read() & fs.write need special treatment due to multiple callback args\n\nexports.read = function (fd, buffer, offset, length, position, callback) {\n  if (typeof callback === 'function') {\n    return fs.read(fd, buffer, offset, length, position, callback)\n  }\n  return new Promise((resolve, reject) => {\n    fs.read(fd, buffer, offset, length, position, (err, bytesRead, buffer) => {\n      if (err) return reject(err)\n      resolve({ bytesRead, buffer })\n    })\n  })\n}\n\n// Function signature can be\n// fs.write(fd, buffer[, offset[, length[, position]]], callback)\n// OR\n// fs.write(fd, string[, position[, encoding]], callback)\n// We need to handle both cases, so we use ...args\nexports.write = function (fd, buffer, ...args) {\n  if (typeof args[args.length - 1] === 'function') {\n    return fs.write(fd, buffer, ...args)\n  }\n\n  return new Promise((resolve, reject) => {\n    fs.write(fd, buffer, ...args, (err, bytesWritten, buffer) => {\n      if (err) return reject(err)\n      resolve({ bytesWritten, buffer })\n    })\n  })\n}\n\n// fs.realpath.native only available in Node v9.2+\nif (typeof fs.realpath.native === 'function') {\n  exports.realpath.native = u(fs.realpath.native)\n}\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_fs-extra@8.1.0@fs-extra/lib/fs/index.js?");

/***/ }),

/***/ "./node_modules/_fs-extra@8.1.0@fs-extra/lib/index.js":
/*!************************************************************!*\
  !*** ./node_modules/_fs-extra@8.1.0@fs-extra/lib/index.js ***!
  \************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nmodule.exports = Object.assign(\n  {},\n  // Export promiseified graceful-fs:\n  __webpack_require__(/*! ./fs */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/fs/index.js\"),\n  // Export extra methods:\n  __webpack_require__(/*! ./copy-sync */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/copy-sync/index.js\"),\n  __webpack_require__(/*! ./copy */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/copy/index.js\"),\n  __webpack_require__(/*! ./empty */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/empty/index.js\"),\n  __webpack_require__(/*! ./ensure */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/ensure/index.js\"),\n  __webpack_require__(/*! ./json */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/json/index.js\"),\n  __webpack_require__(/*! ./mkdirs */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/mkdirs/index.js\"),\n  __webpack_require__(/*! ./move-sync */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/move-sync/index.js\"),\n  __webpack_require__(/*! ./move */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/move/index.js\"),\n  __webpack_require__(/*! ./output */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/output/index.js\"),\n  __webpack_require__(/*! ./path-exists */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/path-exists/index.js\"),\n  __webpack_require__(/*! ./remove */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/remove/index.js\")\n)\n\n// Export fs.promises as a getter property so that we don't trigger\n// ExperimentalWarning before fs.promises is actually accessed.\nconst fs = __webpack_require__(/*! fs */ \"fs\")\nif (Object.getOwnPropertyDescriptor(fs, 'promises')) {\n  Object.defineProperty(module.exports, \"promises\", ({\n    get () { return fs.promises }\n  }))\n}\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_fs-extra@8.1.0@fs-extra/lib/index.js?");

/***/ }),

/***/ "./node_modules/_fs-extra@8.1.0@fs-extra/lib/json/index.js":
/*!*****************************************************************!*\
  !*** ./node_modules/_fs-extra@8.1.0@fs-extra/lib/json/index.js ***!
  \*****************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst u = __webpack_require__(/*! universalify */ \"./node_modules/_universalify@0.1.2@universalify/index.js\").fromCallback\nconst jsonFile = __webpack_require__(/*! ./jsonfile */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/json/jsonfile.js\")\n\njsonFile.outputJson = u(__webpack_require__(/*! ./output-json */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/json/output-json.js\"))\njsonFile.outputJsonSync = __webpack_require__(/*! ./output-json-sync */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/json/output-json-sync.js\")\n// aliases\njsonFile.outputJSON = jsonFile.outputJson\njsonFile.outputJSONSync = jsonFile.outputJsonSync\njsonFile.writeJSON = jsonFile.writeJson\njsonFile.writeJSONSync = jsonFile.writeJsonSync\njsonFile.readJSON = jsonFile.readJson\njsonFile.readJSONSync = jsonFile.readJsonSync\n\nmodule.exports = jsonFile\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_fs-extra@8.1.0@fs-extra/lib/json/index.js?");

/***/ }),

/***/ "./node_modules/_fs-extra@8.1.0@fs-extra/lib/json/jsonfile.js":
/*!********************************************************************!*\
  !*** ./node_modules/_fs-extra@8.1.0@fs-extra/lib/json/jsonfile.js ***!
  \********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst u = __webpack_require__(/*! universalify */ \"./node_modules/_universalify@0.1.2@universalify/index.js\").fromCallback\nconst jsonFile = __webpack_require__(/*! jsonfile */ \"./node_modules/_jsonfile@4.0.0@jsonfile/index.js\")\n\nmodule.exports = {\n  // jsonfile exports\n  readJson: u(jsonFile.readFile),\n  readJsonSync: jsonFile.readFileSync,\n  writeJson: u(jsonFile.writeFile),\n  writeJsonSync: jsonFile.writeFileSync\n}\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_fs-extra@8.1.0@fs-extra/lib/json/jsonfile.js?");

/***/ }),

/***/ "./node_modules/_fs-extra@8.1.0@fs-extra/lib/json/output-json-sync.js":
/*!****************************************************************************!*\
  !*** ./node_modules/_fs-extra@8.1.0@fs-extra/lib/json/output-json-sync.js ***!
  \****************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/_graceful-fs@4.2.8@graceful-fs/graceful-fs.js\")\nconst path = __webpack_require__(/*! path */ \"path\")\nconst mkdir = __webpack_require__(/*! ../mkdirs */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/mkdirs/index.js\")\nconst jsonFile = __webpack_require__(/*! ./jsonfile */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/json/jsonfile.js\")\n\nfunction outputJsonSync (file, data, options) {\n  const dir = path.dirname(file)\n\n  if (!fs.existsSync(dir)) {\n    mkdir.mkdirsSync(dir)\n  }\n\n  jsonFile.writeJsonSync(file, data, options)\n}\n\nmodule.exports = outputJsonSync\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_fs-extra@8.1.0@fs-extra/lib/json/output-json-sync.js?");

/***/ }),

/***/ "./node_modules/_fs-extra@8.1.0@fs-extra/lib/json/output-json.js":
/*!***********************************************************************!*\
  !*** ./node_modules/_fs-extra@8.1.0@fs-extra/lib/json/output-json.js ***!
  \***********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst path = __webpack_require__(/*! path */ \"path\")\nconst mkdir = __webpack_require__(/*! ../mkdirs */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/mkdirs/index.js\")\nconst pathExists = __webpack_require__(/*! ../path-exists */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/path-exists/index.js\").pathExists\nconst jsonFile = __webpack_require__(/*! ./jsonfile */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/json/jsonfile.js\")\n\nfunction outputJson (file, data, options, callback) {\n  if (typeof options === 'function') {\n    callback = options\n    options = {}\n  }\n\n  const dir = path.dirname(file)\n\n  pathExists(dir, (err, itDoes) => {\n    if (err) return callback(err)\n    if (itDoes) return jsonFile.writeJson(file, data, options, callback)\n\n    mkdir.mkdirs(dir, err => {\n      if (err) return callback(err)\n      jsonFile.writeJson(file, data, options, callback)\n    })\n  })\n}\n\nmodule.exports = outputJson\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_fs-extra@8.1.0@fs-extra/lib/json/output-json.js?");

/***/ }),

/***/ "./node_modules/_fs-extra@8.1.0@fs-extra/lib/mkdirs/index.js":
/*!*******************************************************************!*\
  !*** ./node_modules/_fs-extra@8.1.0@fs-extra/lib/mkdirs/index.js ***!
  \*******************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst u = __webpack_require__(/*! universalify */ \"./node_modules/_universalify@0.1.2@universalify/index.js\").fromCallback\nconst mkdirs = u(__webpack_require__(/*! ./mkdirs */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/mkdirs/mkdirs.js\"))\nconst mkdirsSync = __webpack_require__(/*! ./mkdirs-sync */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/mkdirs/mkdirs-sync.js\")\n\nmodule.exports = {\n  mkdirs,\n  mkdirsSync,\n  // alias\n  mkdirp: mkdirs,\n  mkdirpSync: mkdirsSync,\n  ensureDir: mkdirs,\n  ensureDirSync: mkdirsSync\n}\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_fs-extra@8.1.0@fs-extra/lib/mkdirs/index.js?");

/***/ }),

/***/ "./node_modules/_fs-extra@8.1.0@fs-extra/lib/mkdirs/mkdirs-sync.js":
/*!*************************************************************************!*\
  !*** ./node_modules/_fs-extra@8.1.0@fs-extra/lib/mkdirs/mkdirs-sync.js ***!
  \*************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/_graceful-fs@4.2.8@graceful-fs/graceful-fs.js\")\nconst path = __webpack_require__(/*! path */ \"path\")\nconst invalidWin32Path = __webpack_require__(/*! ./win32 */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/mkdirs/win32.js\").invalidWin32Path\n\nconst o777 = parseInt('0777', 8)\n\nfunction mkdirsSync (p, opts, made) {\n  if (!opts || typeof opts !== 'object') {\n    opts = { mode: opts }\n  }\n\n  let mode = opts.mode\n  const xfs = opts.fs || fs\n\n  if (process.platform === 'win32' && invalidWin32Path(p)) {\n    const errInval = new Error(p + ' contains invalid WIN32 path characters.')\n    errInval.code = 'EINVAL'\n    throw errInval\n  }\n\n  if (mode === undefined) {\n    mode = o777 & (~process.umask())\n  }\n  if (!made) made = null\n\n  p = path.resolve(p)\n\n  try {\n    xfs.mkdirSync(p, mode)\n    made = made || p\n  } catch (err0) {\n    if (err0.code === 'ENOENT') {\n      if (path.dirname(p) === p) throw err0\n      made = mkdirsSync(path.dirname(p), opts, made)\n      mkdirsSync(p, opts, made)\n    } else {\n      // In the case of any other error, just see if there's a dir there\n      // already. If so, then hooray!  If not, then something is borked.\n      let stat\n      try {\n        stat = xfs.statSync(p)\n      } catch (err1) {\n        throw err0\n      }\n      if (!stat.isDirectory()) throw err0\n    }\n  }\n\n  return made\n}\n\nmodule.exports = mkdirsSync\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_fs-extra@8.1.0@fs-extra/lib/mkdirs/mkdirs-sync.js?");

/***/ }),

/***/ "./node_modules/_fs-extra@8.1.0@fs-extra/lib/mkdirs/mkdirs.js":
/*!********************************************************************!*\
  !*** ./node_modules/_fs-extra@8.1.0@fs-extra/lib/mkdirs/mkdirs.js ***!
  \********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/_graceful-fs@4.2.8@graceful-fs/graceful-fs.js\")\nconst path = __webpack_require__(/*! path */ \"path\")\nconst invalidWin32Path = __webpack_require__(/*! ./win32 */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/mkdirs/win32.js\").invalidWin32Path\n\nconst o777 = parseInt('0777', 8)\n\nfunction mkdirs (p, opts, callback, made) {\n  if (typeof opts === 'function') {\n    callback = opts\n    opts = {}\n  } else if (!opts || typeof opts !== 'object') {\n    opts = { mode: opts }\n  }\n\n  if (process.platform === 'win32' && invalidWin32Path(p)) {\n    const errInval = new Error(p + ' contains invalid WIN32 path characters.')\n    errInval.code = 'EINVAL'\n    return callback(errInval)\n  }\n\n  let mode = opts.mode\n  const xfs = opts.fs || fs\n\n  if (mode === undefined) {\n    mode = o777 & (~process.umask())\n  }\n  if (!made) made = null\n\n  callback = callback || function () {}\n  p = path.resolve(p)\n\n  xfs.mkdir(p, mode, er => {\n    if (!er) {\n      made = made || p\n      return callback(null, made)\n    }\n    switch (er.code) {\n      case 'ENOENT':\n        if (path.dirname(p) === p) return callback(er)\n        mkdirs(path.dirname(p), opts, (er, made) => {\n          if (er) callback(er, made)\n          else mkdirs(p, opts, callback, made)\n        })\n        break\n\n      // In the case of any other error, just see if there's a dir\n      // there already.  If so, then hooray!  If not, then something\n      // is borked.\n      default:\n        xfs.stat(p, (er2, stat) => {\n          // if the stat fails, then that's super weird.\n          // let the original error be the failure reason.\n          if (er2 || !stat.isDirectory()) callback(er, made)\n          else callback(null, made)\n        })\n        break\n    }\n  })\n}\n\nmodule.exports = mkdirs\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_fs-extra@8.1.0@fs-extra/lib/mkdirs/mkdirs.js?");

/***/ }),

/***/ "./node_modules/_fs-extra@8.1.0@fs-extra/lib/mkdirs/win32.js":
/*!*******************************************************************!*\
  !*** ./node_modules/_fs-extra@8.1.0@fs-extra/lib/mkdirs/win32.js ***!
  \*******************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst path = __webpack_require__(/*! path */ \"path\")\n\n// get drive on windows\nfunction getRootPath (p) {\n  p = path.normalize(path.resolve(p)).split(path.sep)\n  if (p.length > 0) return p[0]\n  return null\n}\n\n// http://stackoverflow.com/a/62888/10333 contains more accurate\n// TODO: expand to include the rest\nconst INVALID_PATH_CHARS = /[<>:\"|?*]/\n\nfunction invalidWin32Path (p) {\n  const rp = getRootPath(p)\n  p = p.replace(rp, '')\n  return INVALID_PATH_CHARS.test(p)\n}\n\nmodule.exports = {\n  getRootPath,\n  invalidWin32Path\n}\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_fs-extra@8.1.0@fs-extra/lib/mkdirs/win32.js?");

/***/ }),

/***/ "./node_modules/_fs-extra@8.1.0@fs-extra/lib/move-sync/index.js":
/*!**********************************************************************!*\
  !*** ./node_modules/_fs-extra@8.1.0@fs-extra/lib/move-sync/index.js ***!
  \**********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nmodule.exports = {\n  moveSync: __webpack_require__(/*! ./move-sync */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/move-sync/move-sync.js\")\n}\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_fs-extra@8.1.0@fs-extra/lib/move-sync/index.js?");

/***/ }),

/***/ "./node_modules/_fs-extra@8.1.0@fs-extra/lib/move-sync/move-sync.js":
/*!**************************************************************************!*\
  !*** ./node_modules/_fs-extra@8.1.0@fs-extra/lib/move-sync/move-sync.js ***!
  \**************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/_graceful-fs@4.2.8@graceful-fs/graceful-fs.js\")\nconst path = __webpack_require__(/*! path */ \"path\")\nconst copySync = __webpack_require__(/*! ../copy-sync */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/copy-sync/index.js\").copySync\nconst removeSync = __webpack_require__(/*! ../remove */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/remove/index.js\").removeSync\nconst mkdirpSync = __webpack_require__(/*! ../mkdirs */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/mkdirs/index.js\").mkdirpSync\nconst stat = __webpack_require__(/*! ../util/stat */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/util/stat.js\")\n\nfunction moveSync (src, dest, opts) {\n  opts = opts || {}\n  const overwrite = opts.overwrite || opts.clobber || false\n\n  const { srcStat } = stat.checkPathsSync(src, dest, 'move')\n  stat.checkParentPathsSync(src, srcStat, dest, 'move')\n  mkdirpSync(path.dirname(dest))\n  return doRename(src, dest, overwrite)\n}\n\nfunction doRename (src, dest, overwrite) {\n  if (overwrite) {\n    removeSync(dest)\n    return rename(src, dest, overwrite)\n  }\n  if (fs.existsSync(dest)) throw new Error('dest already exists.')\n  return rename(src, dest, overwrite)\n}\n\nfunction rename (src, dest, overwrite) {\n  try {\n    fs.renameSync(src, dest)\n  } catch (err) {\n    if (err.code !== 'EXDEV') throw err\n    return moveAcrossDevice(src, dest, overwrite)\n  }\n}\n\nfunction moveAcrossDevice (src, dest, overwrite) {\n  const opts = {\n    overwrite,\n    errorOnExist: true\n  }\n  copySync(src, dest, opts)\n  return removeSync(src)\n}\n\nmodule.exports = moveSync\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_fs-extra@8.1.0@fs-extra/lib/move-sync/move-sync.js?");

/***/ }),

/***/ "./node_modules/_fs-extra@8.1.0@fs-extra/lib/move/index.js":
/*!*****************************************************************!*\
  !*** ./node_modules/_fs-extra@8.1.0@fs-extra/lib/move/index.js ***!
  \*****************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst u = __webpack_require__(/*! universalify */ \"./node_modules/_universalify@0.1.2@universalify/index.js\").fromCallback\nmodule.exports = {\n  move: u(__webpack_require__(/*! ./move */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/move/move.js\"))\n}\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_fs-extra@8.1.0@fs-extra/lib/move/index.js?");

/***/ }),

/***/ "./node_modules/_fs-extra@8.1.0@fs-extra/lib/move/move.js":
/*!****************************************************************!*\
  !*** ./node_modules/_fs-extra@8.1.0@fs-extra/lib/move/move.js ***!
  \****************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/_graceful-fs@4.2.8@graceful-fs/graceful-fs.js\")\nconst path = __webpack_require__(/*! path */ \"path\")\nconst copy = __webpack_require__(/*! ../copy */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/copy/index.js\").copy\nconst remove = __webpack_require__(/*! ../remove */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/remove/index.js\").remove\nconst mkdirp = __webpack_require__(/*! ../mkdirs */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/mkdirs/index.js\").mkdirp\nconst pathExists = __webpack_require__(/*! ../path-exists */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/path-exists/index.js\").pathExists\nconst stat = __webpack_require__(/*! ../util/stat */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/util/stat.js\")\n\nfunction move (src, dest, opts, cb) {\n  if (typeof opts === 'function') {\n    cb = opts\n    opts = {}\n  }\n\n  const overwrite = opts.overwrite || opts.clobber || false\n\n  stat.checkPaths(src, dest, 'move', (err, stats) => {\n    if (err) return cb(err)\n    const { srcStat } = stats\n    stat.checkParentPaths(src, srcStat, dest, 'move', err => {\n      if (err) return cb(err)\n      mkdirp(path.dirname(dest), err => {\n        if (err) return cb(err)\n        return doRename(src, dest, overwrite, cb)\n      })\n    })\n  })\n}\n\nfunction doRename (src, dest, overwrite, cb) {\n  if (overwrite) {\n    return remove(dest, err => {\n      if (err) return cb(err)\n      return rename(src, dest, overwrite, cb)\n    })\n  }\n  pathExists(dest, (err, destExists) => {\n    if (err) return cb(err)\n    if (destExists) return cb(new Error('dest already exists.'))\n    return rename(src, dest, overwrite, cb)\n  })\n}\n\nfunction rename (src, dest, overwrite, cb) {\n  fs.rename(src, dest, err => {\n    if (!err) return cb()\n    if (err.code !== 'EXDEV') return cb(err)\n    return moveAcrossDevice(src, dest, overwrite, cb)\n  })\n}\n\nfunction moveAcrossDevice (src, dest, overwrite, cb) {\n  const opts = {\n    overwrite,\n    errorOnExist: true\n  }\n  copy(src, dest, opts, err => {\n    if (err) return cb(err)\n    return remove(src, cb)\n  })\n}\n\nmodule.exports = move\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_fs-extra@8.1.0@fs-extra/lib/move/move.js?");

/***/ }),

/***/ "./node_modules/_fs-extra@8.1.0@fs-extra/lib/output/index.js":
/*!*******************************************************************!*\
  !*** ./node_modules/_fs-extra@8.1.0@fs-extra/lib/output/index.js ***!
  \*******************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst u = __webpack_require__(/*! universalify */ \"./node_modules/_universalify@0.1.2@universalify/index.js\").fromCallback\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/_graceful-fs@4.2.8@graceful-fs/graceful-fs.js\")\nconst path = __webpack_require__(/*! path */ \"path\")\nconst mkdir = __webpack_require__(/*! ../mkdirs */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/mkdirs/index.js\")\nconst pathExists = __webpack_require__(/*! ../path-exists */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/path-exists/index.js\").pathExists\n\nfunction outputFile (file, data, encoding, callback) {\n  if (typeof encoding === 'function') {\n    callback = encoding\n    encoding = 'utf8'\n  }\n\n  const dir = path.dirname(file)\n  pathExists(dir, (err, itDoes) => {\n    if (err) return callback(err)\n    if (itDoes) return fs.writeFile(file, data, encoding, callback)\n\n    mkdir.mkdirs(dir, err => {\n      if (err) return callback(err)\n\n      fs.writeFile(file, data, encoding, callback)\n    })\n  })\n}\n\nfunction outputFileSync (file, ...args) {\n  const dir = path.dirname(file)\n  if (fs.existsSync(dir)) {\n    return fs.writeFileSync(file, ...args)\n  }\n  mkdir.mkdirsSync(dir)\n  fs.writeFileSync(file, ...args)\n}\n\nmodule.exports = {\n  outputFile: u(outputFile),\n  outputFileSync\n}\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_fs-extra@8.1.0@fs-extra/lib/output/index.js?");

/***/ }),

/***/ "./node_modules/_fs-extra@8.1.0@fs-extra/lib/path-exists/index.js":
/*!************************************************************************!*\
  !*** ./node_modules/_fs-extra@8.1.0@fs-extra/lib/path-exists/index.js ***!
  \************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst u = __webpack_require__(/*! universalify */ \"./node_modules/_universalify@0.1.2@universalify/index.js\").fromPromise\nconst fs = __webpack_require__(/*! ../fs */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/fs/index.js\")\n\nfunction pathExists (path) {\n  return fs.access(path).then(() => true).catch(() => false)\n}\n\nmodule.exports = {\n  pathExists: u(pathExists),\n  pathExistsSync: fs.existsSync\n}\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_fs-extra@8.1.0@fs-extra/lib/path-exists/index.js?");

/***/ }),

/***/ "./node_modules/_fs-extra@8.1.0@fs-extra/lib/remove/index.js":
/*!*******************************************************************!*\
  !*** ./node_modules/_fs-extra@8.1.0@fs-extra/lib/remove/index.js ***!
  \*******************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst u = __webpack_require__(/*! universalify */ \"./node_modules/_universalify@0.1.2@universalify/index.js\").fromCallback\nconst rimraf = __webpack_require__(/*! ./rimraf */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/remove/rimraf.js\")\n\nmodule.exports = {\n  remove: u(rimraf),\n  removeSync: rimraf.sync\n}\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_fs-extra@8.1.0@fs-extra/lib/remove/index.js?");

/***/ }),

/***/ "./node_modules/_fs-extra@8.1.0@fs-extra/lib/remove/rimraf.js":
/*!********************************************************************!*\
  !*** ./node_modules/_fs-extra@8.1.0@fs-extra/lib/remove/rimraf.js ***!
  \********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/_graceful-fs@4.2.8@graceful-fs/graceful-fs.js\")\nconst path = __webpack_require__(/*! path */ \"path\")\nconst assert = __webpack_require__(/*! assert */ \"assert\")\n\nconst isWindows = (process.platform === 'win32')\n\nfunction defaults (options) {\n  const methods = [\n    'unlink',\n    'chmod',\n    'stat',\n    'lstat',\n    'rmdir',\n    'readdir'\n  ]\n  methods.forEach(m => {\n    options[m] = options[m] || fs[m]\n    m = m + 'Sync'\n    options[m] = options[m] || fs[m]\n  })\n\n  options.maxBusyTries = options.maxBusyTries || 3\n}\n\nfunction rimraf (p, options, cb) {\n  let busyTries = 0\n\n  if (typeof options === 'function') {\n    cb = options\n    options = {}\n  }\n\n  assert(p, 'rimraf: missing path')\n  assert.strictEqual(typeof p, 'string', 'rimraf: path should be a string')\n  assert.strictEqual(typeof cb, 'function', 'rimraf: callback function required')\n  assert(options, 'rimraf: invalid options argument provided')\n  assert.strictEqual(typeof options, 'object', 'rimraf: options should be object')\n\n  defaults(options)\n\n  rimraf_(p, options, function CB (er) {\n    if (er) {\n      if ((er.code === 'EBUSY' || er.code === 'ENOTEMPTY' || er.code === 'EPERM') &&\n          busyTries < options.maxBusyTries) {\n        busyTries++\n        const time = busyTries * 100\n        // try again, with the same exact callback as this one.\n        return setTimeout(() => rimraf_(p, options, CB), time)\n      }\n\n      // already gone\n      if (er.code === 'ENOENT') er = null\n    }\n\n    cb(er)\n  })\n}\n\n// Two possible strategies.\n// 1. Assume it's a file.  unlink it, then do the dir stuff on EPERM or EISDIR\n// 2. Assume it's a directory.  readdir, then do the file stuff on ENOTDIR\n//\n// Both result in an extra syscall when you guess wrong.  However, there\n// are likely far more normal files in the world than directories.  This\n// is based on the assumption that a the average number of files per\n// directory is >= 1.\n//\n// If anyone ever complains about this, then I guess the strategy could\n// be made configurable somehow.  But until then, YAGNI.\nfunction rimraf_ (p, options, cb) {\n  assert(p)\n  assert(options)\n  assert(typeof cb === 'function')\n\n  // sunos lets the root user unlink directories, which is... weird.\n  // so we have to lstat here and make sure it's not a dir.\n  options.lstat(p, (er, st) => {\n    if (er && er.code === 'ENOENT') {\n      return cb(null)\n    }\n\n    // Windows can EPERM on stat.  Life is suffering.\n    if (er && er.code === 'EPERM' && isWindows) {\n      return fixWinEPERM(p, options, er, cb)\n    }\n\n    if (st && st.isDirectory()) {\n      return rmdir(p, options, er, cb)\n    }\n\n    options.unlink(p, er => {\n      if (er) {\n        if (er.code === 'ENOENT') {\n          return cb(null)\n        }\n        if (er.code === 'EPERM') {\n          return (isWindows)\n            ? fixWinEPERM(p, options, er, cb)\n            : rmdir(p, options, er, cb)\n        }\n        if (er.code === 'EISDIR') {\n          return rmdir(p, options, er, cb)\n        }\n      }\n      return cb(er)\n    })\n  })\n}\n\nfunction fixWinEPERM (p, options, er, cb) {\n  assert(p)\n  assert(options)\n  assert(typeof cb === 'function')\n  if (er) {\n    assert(er instanceof Error)\n  }\n\n  options.chmod(p, 0o666, er2 => {\n    if (er2) {\n      cb(er2.code === 'ENOENT' ? null : er)\n    } else {\n      options.stat(p, (er3, stats) => {\n        if (er3) {\n          cb(er3.code === 'ENOENT' ? null : er)\n        } else if (stats.isDirectory()) {\n          rmdir(p, options, er, cb)\n        } else {\n          options.unlink(p, cb)\n        }\n      })\n    }\n  })\n}\n\nfunction fixWinEPERMSync (p, options, er) {\n  let stats\n\n  assert(p)\n  assert(options)\n  if (er) {\n    assert(er instanceof Error)\n  }\n\n  try {\n    options.chmodSync(p, 0o666)\n  } catch (er2) {\n    if (er2.code === 'ENOENT') {\n      return\n    } else {\n      throw er\n    }\n  }\n\n  try {\n    stats = options.statSync(p)\n  } catch (er3) {\n    if (er3.code === 'ENOENT') {\n      return\n    } else {\n      throw er\n    }\n  }\n\n  if (stats.isDirectory()) {\n    rmdirSync(p, options, er)\n  } else {\n    options.unlinkSync(p)\n  }\n}\n\nfunction rmdir (p, options, originalEr, cb) {\n  assert(p)\n  assert(options)\n  if (originalEr) {\n    assert(originalEr instanceof Error)\n  }\n  assert(typeof cb === 'function')\n\n  // try to rmdir first, and only readdir on ENOTEMPTY or EEXIST (SunOS)\n  // if we guessed wrong, and it's not a directory, then\n  // raise the original error.\n  options.rmdir(p, er => {\n    if (er && (er.code === 'ENOTEMPTY' || er.code === 'EEXIST' || er.code === 'EPERM')) {\n      rmkids(p, options, cb)\n    } else if (er && er.code === 'ENOTDIR') {\n      cb(originalEr)\n    } else {\n      cb(er)\n    }\n  })\n}\n\nfunction rmkids (p, options, cb) {\n  assert(p)\n  assert(options)\n  assert(typeof cb === 'function')\n\n  options.readdir(p, (er, files) => {\n    if (er) return cb(er)\n\n    let n = files.length\n    let errState\n\n    if (n === 0) return options.rmdir(p, cb)\n\n    files.forEach(f => {\n      rimraf(path.join(p, f), options, er => {\n        if (errState) {\n          return\n        }\n        if (er) return cb(errState = er)\n        if (--n === 0) {\n          options.rmdir(p, cb)\n        }\n      })\n    })\n  })\n}\n\n// this looks simpler, and is strictly *faster*, but will\n// tie up the JavaScript thread and fail on excessively\n// deep directory trees.\nfunction rimrafSync (p, options) {\n  let st\n\n  options = options || {}\n  defaults(options)\n\n  assert(p, 'rimraf: missing path')\n  assert.strictEqual(typeof p, 'string', 'rimraf: path should be a string')\n  assert(options, 'rimraf: missing options')\n  assert.strictEqual(typeof options, 'object', 'rimraf: options should be object')\n\n  try {\n    st = options.lstatSync(p)\n  } catch (er) {\n    if (er.code === 'ENOENT') {\n      return\n    }\n\n    // Windows can EPERM on stat.  Life is suffering.\n    if (er.code === 'EPERM' && isWindows) {\n      fixWinEPERMSync(p, options, er)\n    }\n  }\n\n  try {\n    // sunos lets the root user unlink directories, which is... weird.\n    if (st && st.isDirectory()) {\n      rmdirSync(p, options, null)\n    } else {\n      options.unlinkSync(p)\n    }\n  } catch (er) {\n    if (er.code === 'ENOENT') {\n      return\n    } else if (er.code === 'EPERM') {\n      return isWindows ? fixWinEPERMSync(p, options, er) : rmdirSync(p, options, er)\n    } else if (er.code !== 'EISDIR') {\n      throw er\n    }\n    rmdirSync(p, options, er)\n  }\n}\n\nfunction rmdirSync (p, options, originalEr) {\n  assert(p)\n  assert(options)\n  if (originalEr) {\n    assert(originalEr instanceof Error)\n  }\n\n  try {\n    options.rmdirSync(p)\n  } catch (er) {\n    if (er.code === 'ENOTDIR') {\n      throw originalEr\n    } else if (er.code === 'ENOTEMPTY' || er.code === 'EEXIST' || er.code === 'EPERM') {\n      rmkidsSync(p, options)\n    } else if (er.code !== 'ENOENT') {\n      throw er\n    }\n  }\n}\n\nfunction rmkidsSync (p, options) {\n  assert(p)\n  assert(options)\n  options.readdirSync(p).forEach(f => rimrafSync(path.join(p, f), options))\n\n  if (isWindows) {\n    // We only end up here once we got ENOTEMPTY at least once, and\n    // at this point, we are guaranteed to have removed all the kids.\n    // So, we know that it won't be ENOENT or ENOTDIR or anything else.\n    // try really hard to delete stuff on windows, because it has a\n    // PROFOUNDLY annoying habit of not closing handles promptly when\n    // files are deleted, resulting in spurious ENOTEMPTY errors.\n    const startTime = Date.now()\n    do {\n      try {\n        const ret = options.rmdirSync(p, options)\n        return ret\n      } catch (er) { }\n    } while (Date.now() - startTime < 500) // give up after 500ms\n  } else {\n    const ret = options.rmdirSync(p, options)\n    return ret\n  }\n}\n\nmodule.exports = rimraf\nrimraf.sync = rimrafSync\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_fs-extra@8.1.0@fs-extra/lib/remove/rimraf.js?");

/***/ }),

/***/ "./node_modules/_fs-extra@8.1.0@fs-extra/lib/util/buffer.js":
/*!******************************************************************!*\
  !*** ./node_modules/_fs-extra@8.1.0@fs-extra/lib/util/buffer.js ***!
  \******************************************************************/
/***/ ((module) => {

"use strict";
eval("\n/* eslint-disable node/no-deprecated-api */\nmodule.exports = function (size) {\n  if (typeof Buffer.allocUnsafe === 'function') {\n    try {\n      return Buffer.allocUnsafe(size)\n    } catch (e) {\n      return new Buffer(size)\n    }\n  }\n  return new Buffer(size)\n}\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_fs-extra@8.1.0@fs-extra/lib/util/buffer.js?");

/***/ }),

/***/ "./node_modules/_fs-extra@8.1.0@fs-extra/lib/util/stat.js":
/*!****************************************************************!*\
  !*** ./node_modules/_fs-extra@8.1.0@fs-extra/lib/util/stat.js ***!
  \****************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/_graceful-fs@4.2.8@graceful-fs/graceful-fs.js\")\nconst path = __webpack_require__(/*! path */ \"path\")\n\nconst NODE_VERSION_MAJOR_WITH_BIGINT = 10\nconst NODE_VERSION_MINOR_WITH_BIGINT = 5\nconst NODE_VERSION_PATCH_WITH_BIGINT = 0\nconst nodeVersion = process.versions.node.split('.')\nconst nodeVersionMajor = Number.parseInt(nodeVersion[0], 10)\nconst nodeVersionMinor = Number.parseInt(nodeVersion[1], 10)\nconst nodeVersionPatch = Number.parseInt(nodeVersion[2], 10)\n\nfunction nodeSupportsBigInt () {\n  if (nodeVersionMajor > NODE_VERSION_MAJOR_WITH_BIGINT) {\n    return true\n  } else if (nodeVersionMajor === NODE_VERSION_MAJOR_WITH_BIGINT) {\n    if (nodeVersionMinor > NODE_VERSION_MINOR_WITH_BIGINT) {\n      return true\n    } else if (nodeVersionMinor === NODE_VERSION_MINOR_WITH_BIGINT) {\n      if (nodeVersionPatch >= NODE_VERSION_PATCH_WITH_BIGINT) {\n        return true\n      }\n    }\n  }\n  return false\n}\n\nfunction getStats (src, dest, cb) {\n  if (nodeSupportsBigInt()) {\n    fs.stat(src, { bigint: true }, (err, srcStat) => {\n      if (err) return cb(err)\n      fs.stat(dest, { bigint: true }, (err, destStat) => {\n        if (err) {\n          if (err.code === 'ENOENT') return cb(null, { srcStat, destStat: null })\n          return cb(err)\n        }\n        return cb(null, { srcStat, destStat })\n      })\n    })\n  } else {\n    fs.stat(src, (err, srcStat) => {\n      if (err) return cb(err)\n      fs.stat(dest, (err, destStat) => {\n        if (err) {\n          if (err.code === 'ENOENT') return cb(null, { srcStat, destStat: null })\n          return cb(err)\n        }\n        return cb(null, { srcStat, destStat })\n      })\n    })\n  }\n}\n\nfunction getStatsSync (src, dest) {\n  let srcStat, destStat\n  if (nodeSupportsBigInt()) {\n    srcStat = fs.statSync(src, { bigint: true })\n  } else {\n    srcStat = fs.statSync(src)\n  }\n  try {\n    if (nodeSupportsBigInt()) {\n      destStat = fs.statSync(dest, { bigint: true })\n    } else {\n      destStat = fs.statSync(dest)\n    }\n  } catch (err) {\n    if (err.code === 'ENOENT') return { srcStat, destStat: null }\n    throw err\n  }\n  return { srcStat, destStat }\n}\n\nfunction checkPaths (src, dest, funcName, cb) {\n  getStats(src, dest, (err, stats) => {\n    if (err) return cb(err)\n    const { srcStat, destStat } = stats\n    if (destStat && destStat.ino && destStat.dev && destStat.ino === srcStat.ino && destStat.dev === srcStat.dev) {\n      return cb(new Error('Source and destination must not be the same.'))\n    }\n    if (srcStat.isDirectory() && isSrcSubdir(src, dest)) {\n      return cb(new Error(errMsg(src, dest, funcName)))\n    }\n    return cb(null, { srcStat, destStat })\n  })\n}\n\nfunction checkPathsSync (src, dest, funcName) {\n  const { srcStat, destStat } = getStatsSync(src, dest)\n  if (destStat && destStat.ino && destStat.dev && destStat.ino === srcStat.ino && destStat.dev === srcStat.dev) {\n    throw new Error('Source and destination must not be the same.')\n  }\n  if (srcStat.isDirectory() && isSrcSubdir(src, dest)) {\n    throw new Error(errMsg(src, dest, funcName))\n  }\n  return { srcStat, destStat }\n}\n\n// recursively check if dest parent is a subdirectory of src.\n// It works for all file types including symlinks since it\n// checks the src and dest inodes. It starts from the deepest\n// parent and stops once it reaches the src parent or the root path.\nfunction checkParentPaths (src, srcStat, dest, funcName, cb) {\n  const srcParent = path.resolve(path.dirname(src))\n  const destParent = path.resolve(path.dirname(dest))\n  if (destParent === srcParent || destParent === path.parse(destParent).root) return cb()\n  if (nodeSupportsBigInt()) {\n    fs.stat(destParent, { bigint: true }, (err, destStat) => {\n      if (err) {\n        if (err.code === 'ENOENT') return cb()\n        return cb(err)\n      }\n      if (destStat.ino && destStat.dev && destStat.ino === srcStat.ino && destStat.dev === srcStat.dev) {\n        return cb(new Error(errMsg(src, dest, funcName)))\n      }\n      return checkParentPaths(src, srcStat, destParent, funcName, cb)\n    })\n  } else {\n    fs.stat(destParent, (err, destStat) => {\n      if (err) {\n        if (err.code === 'ENOENT') return cb()\n        return cb(err)\n      }\n      if (destStat.ino && destStat.dev && destStat.ino === srcStat.ino && destStat.dev === srcStat.dev) {\n        return cb(new Error(errMsg(src, dest, funcName)))\n      }\n      return checkParentPaths(src, srcStat, destParent, funcName, cb)\n    })\n  }\n}\n\nfunction checkParentPathsSync (src, srcStat, dest, funcName) {\n  const srcParent = path.resolve(path.dirname(src))\n  const destParent = path.resolve(path.dirname(dest))\n  if (destParent === srcParent || destParent === path.parse(destParent).root) return\n  let destStat\n  try {\n    if (nodeSupportsBigInt()) {\n      destStat = fs.statSync(destParent, { bigint: true })\n    } else {\n      destStat = fs.statSync(destParent)\n    }\n  } catch (err) {\n    if (err.code === 'ENOENT') return\n    throw err\n  }\n  if (destStat.ino && destStat.dev && destStat.ino === srcStat.ino && destStat.dev === srcStat.dev) {\n    throw new Error(errMsg(src, dest, funcName))\n  }\n  return checkParentPathsSync(src, srcStat, destParent, funcName)\n}\n\n// return true if dest is a subdir of src, otherwise false.\n// It only checks the path strings.\nfunction isSrcSubdir (src, dest) {\n  const srcArr = path.resolve(src).split(path.sep).filter(i => i)\n  const destArr = path.resolve(dest).split(path.sep).filter(i => i)\n  return srcArr.reduce((acc, cur, i) => acc && destArr[i] === cur, true)\n}\n\nfunction errMsg (src, dest, funcName) {\n  return `Cannot ${funcName} '${src}' to a subdirectory of itself, '${dest}'.`\n}\n\nmodule.exports = {\n  checkPaths,\n  checkPathsSync,\n  checkParentPaths,\n  checkParentPathsSync,\n  isSrcSubdir\n}\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_fs-extra@8.1.0@fs-extra/lib/util/stat.js?");

/***/ }),

/***/ "./node_modules/_fs-extra@8.1.0@fs-extra/lib/util/utimes.js":
/*!******************************************************************!*\
  !*** ./node_modules/_fs-extra@8.1.0@fs-extra/lib/util/utimes.js ***!
  \******************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/_graceful-fs@4.2.8@graceful-fs/graceful-fs.js\")\nconst os = __webpack_require__(/*! os */ \"os\")\nconst path = __webpack_require__(/*! path */ \"path\")\n\n// HFS, ext{2,3}, FAT do not, Node.js v0.10 does not\nfunction hasMillisResSync () {\n  let tmpfile = path.join('millis-test-sync' + Date.now().toString() + Math.random().toString().slice(2))\n  tmpfile = path.join(os.tmpdir(), tmpfile)\n\n  // 550 millis past UNIX epoch\n  const d = new Date(1435410243862)\n  fs.writeFileSync(tmpfile, 'https://github.com/jprichardson/node-fs-extra/pull/141')\n  const fd = fs.openSync(tmpfile, 'r+')\n  fs.futimesSync(fd, d, d)\n  fs.closeSync(fd)\n  return fs.statSync(tmpfile).mtime > 1435410243000\n}\n\nfunction hasMillisRes (callback) {\n  let tmpfile = path.join('millis-test' + Date.now().toString() + Math.random().toString().slice(2))\n  tmpfile = path.join(os.tmpdir(), tmpfile)\n\n  // 550 millis past UNIX epoch\n  const d = new Date(1435410243862)\n  fs.writeFile(tmpfile, 'https://github.com/jprichardson/node-fs-extra/pull/141', err => {\n    if (err) return callback(err)\n    fs.open(tmpfile, 'r+', (err, fd) => {\n      if (err) return callback(err)\n      fs.futimes(fd, d, d, err => {\n        if (err) return callback(err)\n        fs.close(fd, err => {\n          if (err) return callback(err)\n          fs.stat(tmpfile, (err, stats) => {\n            if (err) return callback(err)\n            callback(null, stats.mtime > 1435410243000)\n          })\n        })\n      })\n    })\n  })\n}\n\nfunction timeRemoveMillis (timestamp) {\n  if (typeof timestamp === 'number') {\n    return Math.floor(timestamp / 1000) * 1000\n  } else if (timestamp instanceof Date) {\n    return new Date(Math.floor(timestamp.getTime() / 1000) * 1000)\n  } else {\n    throw new Error('fs-extra: timeRemoveMillis() unknown parameter type')\n  }\n}\n\nfunction utimesMillis (path, atime, mtime, callback) {\n  // if (!HAS_MILLIS_RES) return fs.utimes(path, atime, mtime, callback)\n  fs.open(path, 'r+', (err, fd) => {\n    if (err) return callback(err)\n    fs.futimes(fd, atime, mtime, futimesErr => {\n      fs.close(fd, closeErr => {\n        if (callback) callback(futimesErr || closeErr)\n      })\n    })\n  })\n}\n\nfunction utimesMillisSync (path, atime, mtime) {\n  const fd = fs.openSync(path, 'r+')\n  fs.futimesSync(fd, atime, mtime)\n  return fs.closeSync(fd)\n}\n\nmodule.exports = {\n  hasMillisRes,\n  hasMillisResSync,\n  timeRemoveMillis,\n  utimesMillis,\n  utimesMillisSync\n}\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_fs-extra@8.1.0@fs-extra/lib/util/utimes.js?");

/***/ }),

/***/ "./node_modules/_graceful-fs@4.2.8@graceful-fs/clone.js":
/*!**************************************************************!*\
  !*** ./node_modules/_graceful-fs@4.2.8@graceful-fs/clone.js ***!
  \**************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = clone\n\nvar getPrototypeOf = Object.getPrototypeOf || function (obj) {\n  return obj.__proto__\n}\n\nfunction clone (obj) {\n  if (obj === null || typeof obj !== 'object')\n    return obj\n\n  if (obj instanceof Object)\n    var copy = { __proto__: getPrototypeOf(obj) }\n  else\n    var copy = Object.create(null)\n\n  Object.getOwnPropertyNames(obj).forEach(function (key) {\n    Object.defineProperty(copy, key, Object.getOwnPropertyDescriptor(obj, key))\n  })\n\n  return copy\n}\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_graceful-fs@4.2.8@graceful-fs/clone.js?");

/***/ }),

/***/ "./node_modules/_graceful-fs@4.2.8@graceful-fs/graceful-fs.js":
/*!********************************************************************!*\
  !*** ./node_modules/_graceful-fs@4.2.8@graceful-fs/graceful-fs.js ***!
  \********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var fs = __webpack_require__(/*! fs */ \"fs\")\nvar polyfills = __webpack_require__(/*! ./polyfills.js */ \"./node_modules/_graceful-fs@4.2.8@graceful-fs/polyfills.js\")\nvar legacy = __webpack_require__(/*! ./legacy-streams.js */ \"./node_modules/_graceful-fs@4.2.8@graceful-fs/legacy-streams.js\")\nvar clone = __webpack_require__(/*! ./clone.js */ \"./node_modules/_graceful-fs@4.2.8@graceful-fs/clone.js\")\n\nvar util = __webpack_require__(/*! util */ \"util\")\n\n/* istanbul ignore next - node 0.x polyfill */\nvar gracefulQueue\nvar previousSymbol\n\n/* istanbul ignore else - node 0.x polyfill */\nif (typeof Symbol === 'function' && typeof Symbol.for === 'function') {\n  gracefulQueue = Symbol.for('graceful-fs.queue')\n  // This is used in testing by future versions\n  previousSymbol = Symbol.for('graceful-fs.previous')\n} else {\n  gracefulQueue = '___graceful-fs.queue'\n  previousSymbol = '___graceful-fs.previous'\n}\n\nfunction noop () {}\n\nfunction publishQueue(context, queue) {\n  Object.defineProperty(context, gracefulQueue, {\n    get: function() {\n      return queue\n    }\n  })\n}\n\nvar debug = noop\nif (util.debuglog)\n  debug = util.debuglog('gfs4')\nelse if (/\\bgfs4\\b/i.test(process.env.NODE_DEBUG || ''))\n  debug = function() {\n    var m = util.format.apply(util, arguments)\n    m = 'GFS4: ' + m.split(/\\n/).join('\\nGFS4: ')\n    console.error(m)\n  }\n\n// Once time initialization\nif (!fs[gracefulQueue]) {\n  // This queue can be shared by multiple loaded instances\n  var queue = global[gracefulQueue] || []\n  publishQueue(fs, queue)\n\n  // Patch fs.close/closeSync to shared queue version, because we need\n  // to retry() whenever a close happens *anywhere* in the program.\n  // This is essential when multiple graceful-fs instances are\n  // in play at the same time.\n  fs.close = (function (fs$close) {\n    function close (fd, cb) {\n      return fs$close.call(fs, fd, function (err) {\n        // This function uses the graceful-fs shared queue\n        if (!err) {\n          resetQueue()\n        }\n\n        if (typeof cb === 'function')\n          cb.apply(this, arguments)\n      })\n    }\n\n    Object.defineProperty(close, previousSymbol, {\n      value: fs$close\n    })\n    return close\n  })(fs.close)\n\n  fs.closeSync = (function (fs$closeSync) {\n    function closeSync (fd) {\n      // This function uses the graceful-fs shared queue\n      fs$closeSync.apply(fs, arguments)\n      resetQueue()\n    }\n\n    Object.defineProperty(closeSync, previousSymbol, {\n      value: fs$closeSync\n    })\n    return closeSync\n  })(fs.closeSync)\n\n  if (/\\bgfs4\\b/i.test(process.env.NODE_DEBUG || '')) {\n    process.on('exit', function() {\n      debug(fs[gracefulQueue])\n      __webpack_require__(/*! assert */ \"assert\").equal(fs[gracefulQueue].length, 0)\n    })\n  }\n}\n\nif (!global[gracefulQueue]) {\n  publishQueue(global, fs[gracefulQueue]);\n}\n\nmodule.exports = patch(clone(fs))\nif (process.env.TEST_GRACEFUL_FS_GLOBAL_PATCH && !fs.__patched) {\n    module.exports = patch(fs)\n    fs.__patched = true;\n}\n\nfunction patch (fs) {\n  // Everything that references the open() function needs to be in here\n  polyfills(fs)\n  fs.gracefulify = patch\n\n  fs.createReadStream = createReadStream\n  fs.createWriteStream = createWriteStream\n  var fs$readFile = fs.readFile\n  fs.readFile = readFile\n  function readFile (path, options, cb) {\n    if (typeof options === 'function')\n      cb = options, options = null\n\n    return go$readFile(path, options, cb)\n\n    function go$readFile (path, options, cb, startTime) {\n      return fs$readFile(path, options, function (err) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([go$readFile, [path, options, cb], err, startTime || Date.now(), Date.now()])\n        else {\n          if (typeof cb === 'function')\n            cb.apply(this, arguments)\n        }\n      })\n    }\n  }\n\n  var fs$writeFile = fs.writeFile\n  fs.writeFile = writeFile\n  function writeFile (path, data, options, cb) {\n    if (typeof options === 'function')\n      cb = options, options = null\n\n    return go$writeFile(path, data, options, cb)\n\n    function go$writeFile (path, data, options, cb, startTime) {\n      return fs$writeFile(path, data, options, function (err) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([go$writeFile, [path, data, options, cb], err, startTime || Date.now(), Date.now()])\n        else {\n          if (typeof cb === 'function')\n            cb.apply(this, arguments)\n        }\n      })\n    }\n  }\n\n  var fs$appendFile = fs.appendFile\n  if (fs$appendFile)\n    fs.appendFile = appendFile\n  function appendFile (path, data, options, cb) {\n    if (typeof options === 'function')\n      cb = options, options = null\n\n    return go$appendFile(path, data, options, cb)\n\n    function go$appendFile (path, data, options, cb, startTime) {\n      return fs$appendFile(path, data, options, function (err) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([go$appendFile, [path, data, options, cb], err, startTime || Date.now(), Date.now()])\n        else {\n          if (typeof cb === 'function')\n            cb.apply(this, arguments)\n        }\n      })\n    }\n  }\n\n  var fs$copyFile = fs.copyFile\n  if (fs$copyFile)\n    fs.copyFile = copyFile\n  function copyFile (src, dest, flags, cb) {\n    if (typeof flags === 'function') {\n      cb = flags\n      flags = 0\n    }\n    return go$copyFile(src, dest, flags, cb)\n\n    function go$copyFile (src, dest, flags, cb, startTime) {\n      return fs$copyFile(src, dest, flags, function (err) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([go$copyFile, [src, dest, flags, cb], err, startTime || Date.now(), Date.now()])\n        else {\n          if (typeof cb === 'function')\n            cb.apply(this, arguments)\n        }\n      })\n    }\n  }\n\n  var fs$readdir = fs.readdir\n  fs.readdir = readdir\n  function readdir (path, options, cb) {\n    if (typeof options === 'function')\n      cb = options, options = null\n\n    return go$readdir(path, options, cb)\n\n    function go$readdir (path, options, cb, startTime) {\n      return fs$readdir(path, options, function (err, files) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([go$readdir, [path, options, cb], err, startTime || Date.now(), Date.now()])\n        else {\n          if (files && files.sort)\n            files.sort()\n\n          if (typeof cb === 'function')\n            cb.call(this, err, files)\n        }\n      })\n    }\n  }\n\n  if (process.version.substr(0, 4) === 'v0.8') {\n    var legStreams = legacy(fs)\n    ReadStream = legStreams.ReadStream\n    WriteStream = legStreams.WriteStream\n  }\n\n  var fs$ReadStream = fs.ReadStream\n  if (fs$ReadStream) {\n    ReadStream.prototype = Object.create(fs$ReadStream.prototype)\n    ReadStream.prototype.open = ReadStream$open\n  }\n\n  var fs$WriteStream = fs.WriteStream\n  if (fs$WriteStream) {\n    WriteStream.prototype = Object.create(fs$WriteStream.prototype)\n    WriteStream.prototype.open = WriteStream$open\n  }\n\n  Object.defineProperty(fs, 'ReadStream', {\n    get: function () {\n      return ReadStream\n    },\n    set: function (val) {\n      ReadStream = val\n    },\n    enumerable: true,\n    configurable: true\n  })\n  Object.defineProperty(fs, 'WriteStream', {\n    get: function () {\n      return WriteStream\n    },\n    set: function (val) {\n      WriteStream = val\n    },\n    enumerable: true,\n    configurable: true\n  })\n\n  // legacy names\n  var FileReadStream = ReadStream\n  Object.defineProperty(fs, 'FileReadStream', {\n    get: function () {\n      return FileReadStream\n    },\n    set: function (val) {\n      FileReadStream = val\n    },\n    enumerable: true,\n    configurable: true\n  })\n  var FileWriteStream = WriteStream\n  Object.defineProperty(fs, 'FileWriteStream', {\n    get: function () {\n      return FileWriteStream\n    },\n    set: function (val) {\n      FileWriteStream = val\n    },\n    enumerable: true,\n    configurable: true\n  })\n\n  function ReadStream (path, options) {\n    if (this instanceof ReadStream)\n      return fs$ReadStream.apply(this, arguments), this\n    else\n      return ReadStream.apply(Object.create(ReadStream.prototype), arguments)\n  }\n\n  function ReadStream$open () {\n    var that = this\n    open(that.path, that.flags, that.mode, function (err, fd) {\n      if (err) {\n        if (that.autoClose)\n          that.destroy()\n\n        that.emit('error', err)\n      } else {\n        that.fd = fd\n        that.emit('open', fd)\n        that.read()\n      }\n    })\n  }\n\n  function WriteStream (path, options) {\n    if (this instanceof WriteStream)\n      return fs$WriteStream.apply(this, arguments), this\n    else\n      return WriteStream.apply(Object.create(WriteStream.prototype), arguments)\n  }\n\n  function WriteStream$open () {\n    var that = this\n    open(that.path, that.flags, that.mode, function (err, fd) {\n      if (err) {\n        that.destroy()\n        that.emit('error', err)\n      } else {\n        that.fd = fd\n        that.emit('open', fd)\n      }\n    })\n  }\n\n  function createReadStream (path, options) {\n    return new fs.ReadStream(path, options)\n  }\n\n  function createWriteStream (path, options) {\n    return new fs.WriteStream(path, options)\n  }\n\n  var fs$open = fs.open\n  fs.open = open\n  function open (path, flags, mode, cb) {\n    if (typeof mode === 'function')\n      cb = mode, mode = null\n\n    return go$open(path, flags, mode, cb)\n\n    function go$open (path, flags, mode, cb, startTime) {\n      return fs$open(path, flags, mode, function (err, fd) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([go$open, [path, flags, mode, cb], err, startTime || Date.now(), Date.now()])\n        else {\n          if (typeof cb === 'function')\n            cb.apply(this, arguments)\n        }\n      })\n    }\n  }\n\n  return fs\n}\n\nfunction enqueue (elem) {\n  debug('ENQUEUE', elem[0].name, elem[1])\n  fs[gracefulQueue].push(elem)\n  retry()\n}\n\n// keep track of the timeout between retry() calls\nvar retryTimer\n\n// reset the startTime and lastTime to now\n// this resets the start of the 60 second overall timeout as well as the\n// delay between attempts so that we'll retry these jobs sooner\nfunction resetQueue () {\n  var now = Date.now()\n  for (var i = 0; i < fs[gracefulQueue].length; ++i) {\n    // entries that are only a length of 2 are from an older version, don't\n    // bother modifying those since they'll be retried anyway.\n    if (fs[gracefulQueue][i].length > 2) {\n      fs[gracefulQueue][i][3] = now // startTime\n      fs[gracefulQueue][i][4] = now // lastTime\n    }\n  }\n  // call retry to make sure we're actively processing the queue\n  retry()\n}\n\nfunction retry () {\n  // clear the timer and remove it to help prevent unintended concurrency\n  clearTimeout(retryTimer)\n  retryTimer = undefined\n\n  if (fs[gracefulQueue].length === 0)\n    return\n\n  var elem = fs[gracefulQueue].shift()\n  var fn = elem[0]\n  var args = elem[1]\n  // these items may be unset if they were added by an older graceful-fs\n  var err = elem[2]\n  var startTime = elem[3]\n  var lastTime = elem[4]\n\n  // if we don't have a startTime we have no way of knowing if we've waited\n  // long enough, so go ahead and retry this item now\n  if (startTime === undefined) {\n    debug('RETRY', fn.name, args)\n    fn.apply(null, args)\n  } else if (Date.now() - startTime >= 60000) {\n    // it's been more than 60 seconds total, bail now\n    debug('TIMEOUT', fn.name, args)\n    var cb = args.pop()\n    if (typeof cb === 'function')\n      cb.call(null, err)\n  } else {\n    // the amount of time between the last attempt and right now\n    var sinceAttempt = Date.now() - lastTime\n    // the amount of time between when we first tried, and when we last tried\n    // rounded up to at least 1\n    var sinceStart = Math.max(lastTime - startTime, 1)\n    // backoff. wait longer than the total time we've been retrying, but only\n    // up to a maximum of 100ms\n    var desiredDelay = Math.min(sinceStart * 1.2, 100)\n    // it's been long enough since the last retry, do it again\n    if (sinceAttempt >= desiredDelay) {\n      debug('RETRY', fn.name, args)\n      fn.apply(null, args.concat([startTime]))\n    } else {\n      // if we can't do this job yet, push it to the end of the queue\n      // and let the next iteration check again\n      fs[gracefulQueue].push(elem)\n    }\n  }\n\n  // schedule our next run if one isn't already scheduled\n  if (retryTimer === undefined) {\n    retryTimer = setTimeout(retry, 0)\n  }\n}\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_graceful-fs@4.2.8@graceful-fs/graceful-fs.js?");

/***/ }),

/***/ "./node_modules/_graceful-fs@4.2.8@graceful-fs/legacy-streams.js":
/*!***********************************************************************!*\
  !*** ./node_modules/_graceful-fs@4.2.8@graceful-fs/legacy-streams.js ***!
  \***********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var Stream = __webpack_require__(/*! stream */ \"stream\").Stream\n\nmodule.exports = legacy\n\nfunction legacy (fs) {\n  return {\n    ReadStream: ReadStream,\n    WriteStream: WriteStream\n  }\n\n  function ReadStream (path, options) {\n    if (!(this instanceof ReadStream)) return new ReadStream(path, options);\n\n    Stream.call(this);\n\n    var self = this;\n\n    this.path = path;\n    this.fd = null;\n    this.readable = true;\n    this.paused = false;\n\n    this.flags = 'r';\n    this.mode = 438; /*=0666*/\n    this.bufferSize = 64 * 1024;\n\n    options = options || {};\n\n    // Mixin options into this\n    var keys = Object.keys(options);\n    for (var index = 0, length = keys.length; index < length; index++) {\n      var key = keys[index];\n      this[key] = options[key];\n    }\n\n    if (this.encoding) this.setEncoding(this.encoding);\n\n    if (this.start !== undefined) {\n      if ('number' !== typeof this.start) {\n        throw TypeError('start must be a Number');\n      }\n      if (this.end === undefined) {\n        this.end = Infinity;\n      } else if ('number' !== typeof this.end) {\n        throw TypeError('end must be a Number');\n      }\n\n      if (this.start > this.end) {\n        throw new Error('start must be <= end');\n      }\n\n      this.pos = this.start;\n    }\n\n    if (this.fd !== null) {\n      process.nextTick(function() {\n        self._read();\n      });\n      return;\n    }\n\n    fs.open(this.path, this.flags, this.mode, function (err, fd) {\n      if (err) {\n        self.emit('error', err);\n        self.readable = false;\n        return;\n      }\n\n      self.fd = fd;\n      self.emit('open', fd);\n      self._read();\n    })\n  }\n\n  function WriteStream (path, options) {\n    if (!(this instanceof WriteStream)) return new WriteStream(path, options);\n\n    Stream.call(this);\n\n    this.path = path;\n    this.fd = null;\n    this.writable = true;\n\n    this.flags = 'w';\n    this.encoding = 'binary';\n    this.mode = 438; /*=0666*/\n    this.bytesWritten = 0;\n\n    options = options || {};\n\n    // Mixin options into this\n    var keys = Object.keys(options);\n    for (var index = 0, length = keys.length; index < length; index++) {\n      var key = keys[index];\n      this[key] = options[key];\n    }\n\n    if (this.start !== undefined) {\n      if ('number' !== typeof this.start) {\n        throw TypeError('start must be a Number');\n      }\n      if (this.start < 0) {\n        throw new Error('start must be >= zero');\n      }\n\n      this.pos = this.start;\n    }\n\n    this.busy = false;\n    this._queue = [];\n\n    if (this.fd === null) {\n      this._open = fs.open;\n      this._queue.push([this._open, this.path, this.flags, this.mode, undefined]);\n      this.flush();\n    }\n  }\n}\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_graceful-fs@4.2.8@graceful-fs/legacy-streams.js?");

/***/ }),

/***/ "./node_modules/_graceful-fs@4.2.8@graceful-fs/polyfills.js":
/*!******************************************************************!*\
  !*** ./node_modules/_graceful-fs@4.2.8@graceful-fs/polyfills.js ***!
  \******************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var constants = __webpack_require__(/*! constants */ \"constants\")\n\nvar origCwd = process.cwd\nvar cwd = null\n\nvar platform = process.env.GRACEFUL_FS_PLATFORM || process.platform\n\nprocess.cwd = function() {\n  if (!cwd)\n    cwd = origCwd.call(process)\n  return cwd\n}\ntry {\n  process.cwd()\n} catch (er) {}\n\n// This check is needed until node.js 12 is required\nif (typeof process.chdir === 'function') {\n  var chdir = process.chdir\n  process.chdir = function (d) {\n    cwd = null\n    chdir.call(process, d)\n  }\n  if (Object.setPrototypeOf) Object.setPrototypeOf(process.chdir, chdir)\n}\n\nmodule.exports = patch\n\nfunction patch (fs) {\n  // (re-)implement some things that are known busted or missing.\n\n  // lchmod, broken prior to 0.6.2\n  // back-port the fix here.\n  if (constants.hasOwnProperty('O_SYMLINK') &&\n      process.version.match(/^v0\\.6\\.[0-2]|^v0\\.5\\./)) {\n    patchLchmod(fs)\n  }\n\n  // lutimes implementation, or no-op\n  if (!fs.lutimes) {\n    patchLutimes(fs)\n  }\n\n  // https://github.com/isaacs/node-graceful-fs/issues/4\n  // Chown should not fail on einval or eperm if non-root.\n  // It should not fail on enosys ever, as this just indicates\n  // that a fs doesn't support the intended operation.\n\n  fs.chown = chownFix(fs.chown)\n  fs.fchown = chownFix(fs.fchown)\n  fs.lchown = chownFix(fs.lchown)\n\n  fs.chmod = chmodFix(fs.chmod)\n  fs.fchmod = chmodFix(fs.fchmod)\n  fs.lchmod = chmodFix(fs.lchmod)\n\n  fs.chownSync = chownFixSync(fs.chownSync)\n  fs.fchownSync = chownFixSync(fs.fchownSync)\n  fs.lchownSync = chownFixSync(fs.lchownSync)\n\n  fs.chmodSync = chmodFixSync(fs.chmodSync)\n  fs.fchmodSync = chmodFixSync(fs.fchmodSync)\n  fs.lchmodSync = chmodFixSync(fs.lchmodSync)\n\n  fs.stat = statFix(fs.stat)\n  fs.fstat = statFix(fs.fstat)\n  fs.lstat = statFix(fs.lstat)\n\n  fs.statSync = statFixSync(fs.statSync)\n  fs.fstatSync = statFixSync(fs.fstatSync)\n  fs.lstatSync = statFixSync(fs.lstatSync)\n\n  // if lchmod/lchown do not exist, then make them no-ops\n  if (!fs.lchmod) {\n    fs.lchmod = function (path, mode, cb) {\n      if (cb) process.nextTick(cb)\n    }\n    fs.lchmodSync = function () {}\n  }\n  if (!fs.lchown) {\n    fs.lchown = function (path, uid, gid, cb) {\n      if (cb) process.nextTick(cb)\n    }\n    fs.lchownSync = function () {}\n  }\n\n  // on Windows, A/V software can lock the directory, causing this\n  // to fail with an EACCES or EPERM if the directory contains newly\n  // created files.  Try again on failure, for up to 60 seconds.\n\n  // Set the timeout this long because some Windows Anti-Virus, such as Parity\n  // bit9, may lock files for up to a minute, causing npm package install\n  // failures. Also, take care to yield the scheduler. Windows scheduling gives\n  // CPU to a busy looping process, which can cause the program causing the lock\n  // contention to be starved of CPU by node, so the contention doesn't resolve.\n  if (platform === \"win32\") {\n    fs.rename = (function (fs$rename) { return function (from, to, cb) {\n      var start = Date.now()\n      var backoff = 0;\n      fs$rename(from, to, function CB (er) {\n        if (er\n            && (er.code === \"EACCES\" || er.code === \"EPERM\")\n            && Date.now() - start < 60000) {\n          setTimeout(function() {\n            fs.stat(to, function (stater, st) {\n              if (stater && stater.code === \"ENOENT\")\n                fs$rename(from, to, CB);\n              else\n                cb(er)\n            })\n          }, backoff)\n          if (backoff < 100)\n            backoff += 10;\n          return;\n        }\n        if (cb) cb(er)\n      })\n    }})(fs.rename)\n  }\n\n  // if read() returns EAGAIN, then just try it again.\n  fs.read = (function (fs$read) {\n    function read (fd, buffer, offset, length, position, callback_) {\n      var callback\n      if (callback_ && typeof callback_ === 'function') {\n        var eagCounter = 0\n        callback = function (er, _, __) {\n          if (er && er.code === 'EAGAIN' && eagCounter < 10) {\n            eagCounter ++\n            return fs$read.call(fs, fd, buffer, offset, length, position, callback)\n          }\n          callback_.apply(this, arguments)\n        }\n      }\n      return fs$read.call(fs, fd, buffer, offset, length, position, callback)\n    }\n\n    // This ensures `util.promisify` works as it does for native `fs.read`.\n    if (Object.setPrototypeOf) Object.setPrototypeOf(read, fs$read)\n    return read\n  })(fs.read)\n\n  fs.readSync = (function (fs$readSync) { return function (fd, buffer, offset, length, position) {\n    var eagCounter = 0\n    while (true) {\n      try {\n        return fs$readSync.call(fs, fd, buffer, offset, length, position)\n      } catch (er) {\n        if (er.code === 'EAGAIN' && eagCounter < 10) {\n          eagCounter ++\n          continue\n        }\n        throw er\n      }\n    }\n  }})(fs.readSync)\n\n  function patchLchmod (fs) {\n    fs.lchmod = function (path, mode, callback) {\n      fs.open( path\n             , constants.O_WRONLY | constants.O_SYMLINK\n             , mode\n             , function (err, fd) {\n        if (err) {\n          if (callback) callback(err)\n          return\n        }\n        // prefer to return the chmod error, if one occurs,\n        // but still try to close, and report closing errors if they occur.\n        fs.fchmod(fd, mode, function (err) {\n          fs.close(fd, function(err2) {\n            if (callback) callback(err || err2)\n          })\n        })\n      })\n    }\n\n    fs.lchmodSync = function (path, mode) {\n      var fd = fs.openSync(path, constants.O_WRONLY | constants.O_SYMLINK, mode)\n\n      // prefer to return the chmod error, if one occurs,\n      // but still try to close, and report closing errors if they occur.\n      var threw = true\n      var ret\n      try {\n        ret = fs.fchmodSync(fd, mode)\n        threw = false\n      } finally {\n        if (threw) {\n          try {\n            fs.closeSync(fd)\n          } catch (er) {}\n        } else {\n          fs.closeSync(fd)\n        }\n      }\n      return ret\n    }\n  }\n\n  function patchLutimes (fs) {\n    if (constants.hasOwnProperty(\"O_SYMLINK\")) {\n      fs.lutimes = function (path, at, mt, cb) {\n        fs.open(path, constants.O_SYMLINK, function (er, fd) {\n          if (er) {\n            if (cb) cb(er)\n            return\n          }\n          fs.futimes(fd, at, mt, function (er) {\n            fs.close(fd, function (er2) {\n              if (cb) cb(er || er2)\n            })\n          })\n        })\n      }\n\n      fs.lutimesSync = function (path, at, mt) {\n        var fd = fs.openSync(path, constants.O_SYMLINK)\n        var ret\n        var threw = true\n        try {\n          ret = fs.futimesSync(fd, at, mt)\n          threw = false\n        } finally {\n          if (threw) {\n            try {\n              fs.closeSync(fd)\n            } catch (er) {}\n          } else {\n            fs.closeSync(fd)\n          }\n        }\n        return ret\n      }\n\n    } else {\n      fs.lutimes = function (_a, _b, _c, cb) { if (cb) process.nextTick(cb) }\n      fs.lutimesSync = function () {}\n    }\n  }\n\n  function chmodFix (orig) {\n    if (!orig) return orig\n    return function (target, mode, cb) {\n      return orig.call(fs, target, mode, function (er) {\n        if (chownErOk(er)) er = null\n        if (cb) cb.apply(this, arguments)\n      })\n    }\n  }\n\n  function chmodFixSync (orig) {\n    if (!orig) return orig\n    return function (target, mode) {\n      try {\n        return orig.call(fs, target, mode)\n      } catch (er) {\n        if (!chownErOk(er)) throw er\n      }\n    }\n  }\n\n\n  function chownFix (orig) {\n    if (!orig) return orig\n    return function (target, uid, gid, cb) {\n      return orig.call(fs, target, uid, gid, function (er) {\n        if (chownErOk(er)) er = null\n        if (cb) cb.apply(this, arguments)\n      })\n    }\n  }\n\n  function chownFixSync (orig) {\n    if (!orig) return orig\n    return function (target, uid, gid) {\n      try {\n        return orig.call(fs, target, uid, gid)\n      } catch (er) {\n        if (!chownErOk(er)) throw er\n      }\n    }\n  }\n\n  function statFix (orig) {\n    if (!orig) return orig\n    // Older versions of Node erroneously returned signed integers for\n    // uid + gid.\n    return function (target, options, cb) {\n      if (typeof options === 'function') {\n        cb = options\n        options = null\n      }\n      function callback (er, stats) {\n        if (stats) {\n          if (stats.uid < 0) stats.uid += 0x100000000\n          if (stats.gid < 0) stats.gid += 0x100000000\n        }\n        if (cb) cb.apply(this, arguments)\n      }\n      return options ? orig.call(fs, target, options, callback)\n        : orig.call(fs, target, callback)\n    }\n  }\n\n  function statFixSync (orig) {\n    if (!orig) return orig\n    // Older versions of Node erroneously returned signed integers for\n    // uid + gid.\n    return function (target, options) {\n      var stats = options ? orig.call(fs, target, options)\n        : orig.call(fs, target)\n      if (stats.uid < 0) stats.uid += 0x100000000\n      if (stats.gid < 0) stats.gid += 0x100000000\n      return stats;\n    }\n  }\n\n  // ENOSYS means that the fs doesn't support the op. Just ignore\n  // that, because it doesn't matter.\n  //\n  // if there's no getuid, or if getuid() is something other\n  // than 0, and the error is EINVAL or EPERM, then just ignore\n  // it.\n  //\n  // This specific case is a silent failure in cp, install, tar,\n  // and most other unix tools that manage permissions.\n  //\n  // When running as root, or if other types of errors are\n  // encountered, then it's strict.\n  function chownErOk (er) {\n    if (!er)\n      return true\n\n    if (er.code === \"ENOSYS\")\n      return true\n\n    var nonroot = !process.getuid || process.getuid() !== 0\n    if (nonroot) {\n      if (er.code === \"EINVAL\" || er.code === \"EPERM\")\n        return true\n    }\n\n    return false\n  }\n}\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_graceful-fs@4.2.8@graceful-fs/polyfills.js?");

/***/ }),

/***/ "./node_modules/_jsonfile@4.0.0@jsonfile/index.js":
/*!********************************************************!*\
  !*** ./node_modules/_jsonfile@4.0.0@jsonfile/index.js ***!
  \********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var _fs\ntry {\n  _fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/_graceful-fs@4.2.8@graceful-fs/graceful-fs.js\")\n} catch (_) {\n  _fs = __webpack_require__(/*! fs */ \"fs\")\n}\n\nfunction readFile (file, options, callback) {\n  if (callback == null) {\n    callback = options\n    options = {}\n  }\n\n  if (typeof options === 'string') {\n    options = {encoding: options}\n  }\n\n  options = options || {}\n  var fs = options.fs || _fs\n\n  var shouldThrow = true\n  if ('throws' in options) {\n    shouldThrow = options.throws\n  }\n\n  fs.readFile(file, options, function (err, data) {\n    if (err) return callback(err)\n\n    data = stripBom(data)\n\n    var obj\n    try {\n      obj = JSON.parse(data, options ? options.reviver : null)\n    } catch (err2) {\n      if (shouldThrow) {\n        err2.message = file + ': ' + err2.message\n        return callback(err2)\n      } else {\n        return callback(null, null)\n      }\n    }\n\n    callback(null, obj)\n  })\n}\n\nfunction readFileSync (file, options) {\n  options = options || {}\n  if (typeof options === 'string') {\n    options = {encoding: options}\n  }\n\n  var fs = options.fs || _fs\n\n  var shouldThrow = true\n  if ('throws' in options) {\n    shouldThrow = options.throws\n  }\n\n  try {\n    var content = fs.readFileSync(file, options)\n    content = stripBom(content)\n    return JSON.parse(content, options.reviver)\n  } catch (err) {\n    if (shouldThrow) {\n      err.message = file + ': ' + err.message\n      throw err\n    } else {\n      return null\n    }\n  }\n}\n\nfunction stringify (obj, options) {\n  var spaces\n  var EOL = '\\n'\n  if (typeof options === 'object' && options !== null) {\n    if (options.spaces) {\n      spaces = options.spaces\n    }\n    if (options.EOL) {\n      EOL = options.EOL\n    }\n  }\n\n  var str = JSON.stringify(obj, options ? options.replacer : null, spaces)\n\n  return str.replace(/\\n/g, EOL) + EOL\n}\n\nfunction writeFile (file, obj, options, callback) {\n  if (callback == null) {\n    callback = options\n    options = {}\n  }\n  options = options || {}\n  var fs = options.fs || _fs\n\n  var str = ''\n  try {\n    str = stringify(obj, options)\n  } catch (err) {\n    // Need to return whether a callback was passed or not\n    if (callback) callback(err, null)\n    return\n  }\n\n  fs.writeFile(file, str, options, callback)\n}\n\nfunction writeFileSync (file, obj, options) {\n  options = options || {}\n  var fs = options.fs || _fs\n\n  var str = stringify(obj, options)\n  // not sure if fs.writeFileSync returns anything, but just in case\n  return fs.writeFileSync(file, str, options)\n}\n\nfunction stripBom (content) {\n  // we do this because JSON.parse would convert it to a utf8 string if encoding wasn't specified\n  if (Buffer.isBuffer(content)) content = content.toString('utf8')\n  content = content.replace(/^\\uFEFF/, '')\n  return content\n}\n\nvar jsonfile = {\n  readFile: readFile,\n  readFileSync: readFileSync,\n  writeFile: writeFile,\n  writeFileSync: writeFileSync\n}\n\nmodule.exports = jsonfile\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_jsonfile@4.0.0@jsonfile/index.js?");

/***/ }),

/***/ "./src/model-utils/dataset.ts":
/*!************************************!*\
  !*** ./src/model-utils/dataset.ts ***!
  \************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nvar __spreadArray = (this && this.__spreadArray) || function (to, from) {\n    for (var i = 0, il = from.length, j = to.length; i < il; i++, j++)\n        to[j] = from[i];\n    return to;\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.transform_images = exports.transform_targets_for_output = exports.getSingle = exports.transformTargets = void 0;\nvar loss_1 = __webpack_require__(/*! ./loss */ \"./src/model-utils/loss.ts\");\nvar model_1 = __webpack_require__(/*! ./model */ \"./src/model-utils/model.ts\");\nvar tf = __importStar(__webpack_require__(/*! @tensorflow/tfjs-node */ \"@tensorflow/tfjs-node\"));\nfunction transformTargets(y_train, anchors, size) {\n    return __awaiter(this, void 0, void 0, function () {\n        var y_outs, grid_size, _i, _a, anchor_idxs, _b, _c;\n        return __generator(this, function (_d) {\n            switch (_d.label) {\n                case 0:\n                    y_outs = [];\n                    grid_size = Math.floor(size / 32);\n                    y_train = tf.tidy(function () {\n                        anchors = tf.cast(anchors, 'float32');\n                        var anchor_area = tf.mul(loss_1.getLastIndex(anchors, 0), loss_1.getLastIndex(anchors, 1));\n                        var box_wh = tf.sub(y_train.slice([0, 0, 2], [-1, -1, 2]), y_train.slice([0, 0, 0], [-1, -1, 2]));\n                        box_wh = tf.tile(tf.expandDims(box_wh, -2), [1, 1, anchors.shape[0], 1]);\n                        var box_area = tf.mul(loss_1.getLastIndex(box_wh, 0), loss_1.getLastIndex(box_wh, 1));\n                        var intersection = tf.mul(tf.minimum(loss_1.getLastIndex(box_wh, 0), loss_1.getLastIndex(anchors, 0)), tf.minimum(loss_1.getLastIndex(box_wh, 1), loss_1.getLastIndex(anchors, 1)));\n                        var iou = tf.div(intersection, tf.sub(tf.add(box_area, anchor_area), intersection));\n                        var anchor_idx = tf.cast(tf.argMax(iou, -1), 'float32');\n                        anchor_idx = tf.expandDims(anchor_idx, -1);\n                        y_train = tf.concat([y_train, anchor_idx], -1);\n                        return y_train;\n                    });\n                    _i = 0, _a = model_1.getConstants().yolo_tiny_anchor_masks;\n                    _d.label = 1;\n                case 1:\n                    if (!(_i < _a.length)) return [3 /*break*/, 4];\n                    anchor_idxs = _a[_i];\n                    _c = (_b = y_outs).push;\n                    return [4 /*yield*/, transform_targets_for_output(y_train, grid_size, anchor_idxs)];\n                case 2:\n                    _c.apply(_b, [(_d.sent())]);\n                    grid_size *= 2;\n                    _d.label = 3;\n                case 3:\n                    _i++;\n                    return [3 /*break*/, 1];\n                case 4: return [2 /*return*/, y_outs];\n            }\n        });\n    });\n}\nexports.transformTargets = transformTargets;\nfunction getSingle(x, position) {\n    return x.slice(position, new Array(position.length).fill(1)).reshape([1]);\n}\nexports.getSingle = getSingle;\nfunction transform_targets_for_output(y_true, grid_size, anchor_idxss) {\n    return __awaiter(this, void 0, void 0, function () {\n        var N, y_true_out, anchor_idxs, indexes, updates, i, j, anchor_eq, box, box_xy, anchor_idx, _a, _b, grid_xy, buffer, i, index, update, j;\n        return __generator(this, function (_c) {\n            switch (_c.label) {\n                case 0:\n                    N = y_true.shape[0];\n                    y_true_out = tf.zeros([N, grid_size, grid_size, anchor_idxss.length, 6]);\n                    anchor_idxs = tf.tensor(anchor_idxss);\n                    anchor_idxs = tf.cast(anchor_idxs, 'int32');\n                    indexes = [];\n                    updates = [];\n                    i = 0;\n                    _c.label = 1;\n                case 1:\n                    if (!(i < N)) return [3 /*break*/, 6];\n                    j = 0;\n                    _c.label = 2;\n                case 2:\n                    if (!(j < y_true.shape[1])) return [3 /*break*/, 5];\n                    if (tf.equal(getSingle(y_true, [i, j, 2]), 0).dataSync()[0]) {\n                        return [3 /*break*/, 4];\n                    }\n                    anchor_eq = tf.equal(anchor_idxs, tf.cast(getSingle(y_true, [i, j, 5]), 'int32'));\n                    if (!tf.any(anchor_eq).dataSync()[0]) return [3 /*break*/, 4];\n                    box = y_true.slice([i, j, 0], [1, 1, 4]).reshape([4]);\n                    box_xy = tf.div(tf.add(y_true.slice([i, j, 0], [1, 1, 2]).reshape([2]), y_true.slice([i, j, 2], [1, 1, 2]).reshape([2])), 2);\n                    _b = (_a = tf).cast;\n                    return [4 /*yield*/, tf.whereAsync(anchor_eq)];\n                case 3:\n                    anchor_idx = _b.apply(_a, [(_c.sent()), 'int32']);\n                    grid_xy = tf.cast(tf.floorDiv(box_xy, tf.div(1, grid_size)), 'int32');\n                    indexes.push([i, grid_xy.slice([1], [1]).reshape([1]).dataSync()[0], grid_xy.slice([0], [1]).reshape([1]).dataSync()[0], anchor_idx.slice([0, 0], [1, 1]).reshape([1]).dataSync()[0]]);\n                    updates.push([\n                        box.slice([0], [1]).reshape([1]).dataSync()[0],\n                        box.slice([1], [1]).reshape([1]).dataSync()[0],\n                        box.slice([2], [1]).reshape([1]).dataSync()[0],\n                        box.slice([3], [1]).reshape([1]).dataSync()[0],\n                        1,\n                        y_true.slice([i, j, 4], [1, 1, 1]).reshape([1]).dataSync()[0]\n                    ]);\n                    _c.label = 4;\n                case 4:\n                    j++;\n                    return [3 /*break*/, 2];\n                case 5:\n                    i++;\n                    return [3 /*break*/, 1];\n                case 6: return [4 /*yield*/, y_true_out.bufferSync()];\n                case 7:\n                    buffer = _c.sent();\n                    for (i = 0; i < indexes.length; i++) {\n                        index = indexes[i];\n                        update = updates[i];\n                        for (j = 0; j < update.length; j++) {\n                            buffer.set.apply(buffer, __spreadArray([update[j]], (index.concat([j]))));\n                        }\n                    }\n                    return [2 /*return*/, buffer.toTensor()];\n            }\n        });\n    });\n}\nexports.transform_targets_for_output = transform_targets_for_output;\nfunction transform_images(image, size) {\n    return tf.div(tf.image.resizeBilinear(image, size), 255);\n}\nexports.transform_images = transform_images;\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./src/model-utils/dataset.ts?");

/***/ }),

/***/ "./src/model-utils/loss.ts":
/*!*********************************!*\
  !*** ./src/model-utils/loss.ts ***!
  \*********************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.lossWrap = exports.getLastIndex = exports.yolo_boxes = exports.yolo_nms = void 0;\nvar utils_1 = __webpack_require__(/*! ./utils */ \"./src/model-utils/utils.ts\");\nvar tf = __importStar(__webpack_require__(/*! @tensorflow/tfjs-node */ \"@tensorflow/tfjs-node\"));\nfunction _meshgrid(n_a, n_b) {\n    var repeatTensor = [];\n    for (var i = 0; i < n_b; i++) {\n        repeatTensor.push.apply(repeatTensor, new Array(n_a).fill(i));\n    }\n    return [\n        tf.reshape(tf.tile(tf.range(0, n_a), [n_b]), [n_b, n_a]),\n        tf.reshape(tf.tensor(repeatTensor), [n_b, n_a])\n    ];\n}\nfunction yolo_nms(outputs) {\n    var b = [], c = [], t = [];\n    for (var _i = 0, outputs_1 = outputs; _i < outputs_1.length; _i++) {\n        var o = outputs_1[_i];\n        b.push(tf.reshape(o[0], [o[0].shape[0], -1, o[0].shape[o[0].shape.length - 1]]));\n        c.push(tf.reshape(o[1], [o[1].shape[0], -1, o[1].shape[o[1].shape.length - 1]]));\n        t.push(tf.reshape(o[2], [o[2].shape[0], -1, o[2].shape[o[2].shape.length - 1]]));\n    }\n    var bbox = tf.concat(b, 1);\n    var confidence = tf.concat(c, 1);\n    var class_probs = tf.concat(t, 1);\n    var scores = tf.mul(confidence, class_probs);\n    var dscores = tf.squeeze(scores, [0]);\n    scores = tf.max(dscores, [1]);\n    bbox = tf.reshape(bbox, [-1, 4]);\n    var classes = tf.argMax(dscores, 1);\n    var nonMaxScores = tf.image.nonMaxSuppressionWithScore(bbox, scores, 16, 0.5, 0.5);\n    var selectedIndices = nonMaxScores.selectedIndices, selectedScores = nonMaxScores.selectedScores;\n    var num_valid_nms_boxes = selectedIndices.shape[0];\n    selectedIndices = tf.concat([selectedIndices, tf.zeros([16 - num_valid_nms_boxes], 'int32')], 0);\n    selectedScores = tf.concat([selectedScores, tf.zeros([16 - num_valid_nms_boxes], 'float32')], -1);\n    var boxes = tf.gather(bbox, selectedIndices);\n    boxes = tf.expandDims(boxes, 0);\n    scores = selectedScores;\n    scores = tf.expandDims(scores, 0);\n    classes = tf.gather(classes, selectedIndices);\n    classes = tf.expandDims(classes, 0);\n    var valid_detections = num_valid_nms_boxes;\n    return {\n        boxes: boxes,\n        scores: scores,\n        classes: classes,\n        valid_detections: valid_detections\n    };\n}\nexports.yolo_nms = yolo_nms;\nfunction yolo_boxes(pred, anchors, classes) {\n    var gridSize = pred.shape.slice(1, 3);\n    var _a = tf.split(pred, [2, 2, 1, classes], -1), box_xy = _a[0], box_wh = _a[1], objectness = _a[2], class_probs = _a[3];\n    box_xy = tf.sigmoid(box_xy);\n    objectness = tf.sigmoid(objectness);\n    class_probs = tf.sigmoid(class_probs);\n    var pred_box = tf.concat([box_xy, box_wh], -1);\n    var grid = _meshgrid(gridSize[1], gridSize[0]);\n    grid = tf.expandDims(tf.stack(grid, -1), 2);\n    box_xy = tf.div(tf.add(box_xy, tf.cast(grid, 'float32')), tf.cast(gridSize, 'float32'));\n    box_wh = tf.mul(tf.exp(box_wh), anchors);\n    var box_x1y1 = tf.sub(box_xy, tf.div(box_wh, 2));\n    var box_x2y2 = tf.add(box_xy, tf.div(box_wh, 2));\n    var bbox = tf.concat([box_x1y1, box_x2y2], -1);\n    return [bbox, objectness, class_probs, pred_box];\n}\nexports.yolo_boxes = yolo_boxes;\nfunction broadcast_dynamic_shape(shape1, shape2) {\n    var arr = [];\n    var lengthMax = Math.max(shape1.length, shape2.length);\n    shape1 = (new Array(lengthMax - shape1.length).fill(-1)).concat(shape1);\n    shape2 = (new Array(lengthMax - shape2.length).fill(-1)).concat(shape2);\n    for (var i = 0; i < lengthMax; i++) {\n        if (shape1[i] == 0 || shape2[i] == 0) {\n            arr[i] = 0;\n            continue;\n        }\n        arr[i] = Math.max(shape1[i], shape2[i]);\n    }\n    return arr;\n}\nfunction getLastIndex(arr, num) {\n    var shape = arr.shape;\n    var one = new Array(shape.length).fill(0);\n    one[one.length - 1] = num;\n    var two = new Array(shape.length).fill(-1);\n    two[two.length - 1] = 1;\n    return arr.slice(one, two).reshape(arr.shape.slice(0, arr.shape.length - 1));\n}\nexports.getLastIndex = getLastIndex;\nfunction broadcast_iou(box_1, box_2) {\n    var originShapeFirst = box_2.shape[0];\n    box_1 = tf.expandDims(box_1, -2);\n    box_2 = tf.expandDims(box_2, 0);\n    var new_shape = broadcast_dynamic_shape(box_1.shape, box_2.shape);\n    if (originShapeFirst == 0) {\n        return tf.tensor([], new_shape.slice(0, new_shape.length - 1));\n    }\n    box_1 = utils_1.broadcastTo(box_1, new_shape);\n    box_2 = utils_1.broadcastTo(box_2, new_shape);\n    var int_w = tf.maximum(tf.sub(tf.minimum(getLastIndex(box_1, 2), getLastIndex(box_2, 2)), tf.maximum(getLastIndex(box_1, 0), getLastIndex(box_2, 0))), 0);\n    var int_h = tf.maximum(tf.sub(tf.minimum(getLastIndex(box_1, 3), getLastIndex(box_2, 3)), tf.maximum(getLastIndex(box_1, 1), getLastIndex(box_2, 1))), 0);\n    var int_area = tf.mul(int_w, int_h);\n    var box_1_area = tf.mul(tf.sub(getLastIndex(box_1, 2), getLastIndex(box_1, 0)), tf.sub(getLastIndex(box_1, 3), getLastIndex(box_1, 1)));\n    var box_2_area = tf.mul(tf.sub(getLastIndex(box_2, 2), getLastIndex(box_2, 0)), tf.sub(getLastIndex(box_2, 3), getLastIndex(box_2, 1)));\n    return tf.div(int_area, tf.sub(tf.add(box_1_area, box_2_area), int_area));\n}\nfunction lossWrap(anchors, classes, ignore_thresh) {\n    if (ignore_thresh === void 0) { ignore_thresh = 0.5; }\n    return function yoloLoss(yTrue, yPred) {\n        var loss = tf.tidy(function () {\n            var _a = yolo_boxes(yPred, anchors, classes), pred_box = _a[0], pred_obj = _a[1], pred_class = _a[2], pred_xywh = _a[3];\n            var pred_xy = pred_xywh.slice([0, 0, 0, 0, 0], [-1, -1, -1, -1, 2]);\n            var pred_wh = pred_xywh.slice([0, 0, 0, 0, 2], [-1, -1, -1, -1, 2]);\n            var _b = tf.split(yTrue, [4, 1, 1], -1), true_box = _b[0], true_obj = _b[1], true_class_idx = _b[2];\n            var trueBox02 = true_box.slice([0, 0, 0, 0, 0], [-1, -1, -1, -1, 2]);\n            var trueBox24 = true_box.slice([0, 0, 0, 0, 2], [-1, -1, -1, -1, 2]);\n            var true_xy = tf.div(tf.add(trueBox02, trueBox24), 2);\n            var true_wh = tf.sub(trueBox24, trueBox02);\n            var true_wh0 = true_wh.slice([0, 0, 0, 0, 0], [-1, -1, -1, -1, 1]).reshape(true_wh.shape.slice(0, 4));\n            var true_wh1 = true_wh.slice([0, 0, 0, 0, 1], [-1, -1, -1, -1, 1]).reshape(true_wh.shape.slice(0, 4));\n            var box_loss_scale = tf.sub(2, tf.mul(true_wh0, true_wh1));\n            var grid_size = yTrue.shape[1];\n            var gridA = tf.meshgrid(tf.range(0, grid_size), tf.range(0, grid_size));\n            var grid = tf.expandDims(tf.stack(gridA, -1), 2);\n            true_xy = tf.sub(tf.mul(true_xy, tf.cast(grid_size, 'float32')), tf.cast(grid, 'float32'));\n            true_wh = tf.log(tf.div(true_wh, anchors));\n            true_wh = tf.where(tf.isInf(true_wh), tf.zerosLike(true_wh), true_wh);\n            true_wh = tf.where(tf.isNaN(true_wh), tf.zerosLike(true_wh), true_wh);\n            var obj_mask = tf.squeeze(true_obj, [-1]);\n            var best_iou_arr = [];\n            for (var i = 0; i < pred_box.shape[0]; i++) {\n                var cur_pred_box = pred_box.slice([i], [1]).reshape(pred_box.shape.slice(1));\n                var cur_true_box = true_box.slice([i], [1]).reshape(true_box.shape.slice(1));\n                var cur_obj_mask = obj_mask.slice([i], [1]).reshape(obj_mask.shape.slice(1));\n                var boolean_mask = broadcast_iou(cur_pred_box, utils_1.booleanMask(cur_true_box, tf.cast(cur_obj_mask, 'bool')));\n                var reduceMax = tf.max(boolean_mask, -1);\n                best_iou_arr.push(reduceMax);\n            }\n            var best_iou = tf.stack(best_iou_arr);\n            var ignore_mask = tf.cast(tf.cast(tf.sub(tf.minimum(best_iou, ignore_thresh), ignore_thresh), 'bool'), 'float32');\n            var xy_loss = tf.mul(tf.mul(obj_mask, box_loss_scale), tf.sum(tf.square(tf.sub(true_xy, pred_xy)), -1));\n            var wh_loss = tf.mul(tf.mul(obj_mask, box_loss_scale), tf.sum(tf.square(tf.sub(true_wh, pred_wh)), -1));\n            var obj_loss = tf.metrics.binaryCrossentropy(true_obj, pred_obj);\n            obj_loss = tf.add(tf.mul(obj_mask, obj_loss), tf.mul(tf.mul(tf.sub(1, obj_mask), ignore_mask), obj_loss));\n            var class_loss = tf.mul(obj_mask, utils_1.sparseCategoricalCrossentropy(true_class_idx, pred_class));\n            xy_loss = tf.sum(xy_loss, [1, 2, 3]);\n            wh_loss = tf.sum(wh_loss, [1, 2, 3]);\n            obj_loss = tf.sum(obj_loss, [1, 2, 3]);\n            class_loss = tf.sum(class_loss, [1, 2, 3]);\n            return tf.sum(tf.add(tf.add(tf.add(xy_loss, wh_loss), obj_loss), class_loss));\n        });\n        return loss;\n    };\n}\nexports.lossWrap = lossWrap;\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./src/model-utils/loss.ts?");

/***/ }),

/***/ "./src/model-utils/model.ts":
/*!**********************************!*\
  !*** ./src/model-utils/model.ts ***!
  \**********************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.tinyYoloBody = exports.getConstants = void 0;\nvar tf = __importStar(__webpack_require__(/*! @tensorflow/tfjs-node */ \"@tensorflow/tfjs-node\"));\nfunction getConstants() {\n    var yolo_tiny_anchors1 = tf.div(tf.tensor([\n        [81, 82], [135, 169], [344, 319]\n    ], [3, 2], 'float32'), 416);\n    var yolo_tiny_anchors2 = tf.div(tf.tensor([[10, 14], [23, 27], [37, 58]], [3, 2], 'float32'), 416);\n    var yolo_tiny_anchor_masks = [[3, 4, 5], [0, 1, 2]];\n    var yolo_tiny_anchors = tf.div(tf.tensor([[10, 14], [23, 27], [37, 58],\n        [81, 82], [135, 169], [344, 319]], [6, 2], 'float32'), 416);\n    return {\n        yolo_tiny_anchors1: yolo_tiny_anchors1,\n        yolo_tiny_anchors2: yolo_tiny_anchors2,\n        yolo_tiny_anchor_masks: yolo_tiny_anchor_masks,\n        yolo_tiny_anchors: yolo_tiny_anchors\n    };\n}\nexports.getConstants = getConstants;\nfunction DarknetConv2D_BN_Leaky(input, filters, kernelSize) {\n    var temp = tf.layers.conv2d({\n        filters: filters,\n        kernelSize: kernelSize,\n        useBias: false,\n        kernelRegularizer: tf.regularizers.l2({\n            l2: 5e-4\n        }),\n        kernelInitializer: 'glorotUniform',\n        padding: 'same',\n        biasInitializer: 'zeros',\n        dilationRate: [1, 1],\n        strides: 1\n    }).apply(input);\n    temp = tf.layers.batchNormalization().apply(temp);\n    temp = tf.layers.leakyReLU({\n        alpha: 0.1\n    }).apply(temp);\n    return temp;\n}\nfunction DarknetConv2D(input, filters, kernelSize) {\n    var temp = tf.layers.conv2d({\n        filters: filters,\n        kernelSize: kernelSize,\n        kernelRegularizer: tf.regularizers.l2({\n            l2: 5e-4\n        }),\n        kernelInitializer: 'glorotUniform',\n        padding: 'same',\n        biasInitializer: 'zeros',\n        dilationRate: [1, 1],\n        strides: 1\n    }).apply(input);\n    return temp;\n}\nfunction maxPooling2d(input, poolSize, strides) {\n    var temp = tf.layers.maxPooling2d({\n        poolSize: poolSize,\n        strides: strides,\n        padding: 'same',\n        dataFormat: 'channelsLast'\n    }).apply(input);\n    return temp;\n}\nfunction DarknetTiny(name) {\n    if (name === void 0) { name = ''; }\n    var inputs = tf.layers.input({\n        shape: [null, null, 3]\n    });\n    var temp = inputs;\n    temp = DarknetConv2D_BN_Leaky(temp, 16, [3, 3]);\n    temp = maxPooling2d(temp, [2, 2], [2, 2]);\n    temp = DarknetConv2D_BN_Leaky(temp, 32, [3, 3]);\n    temp = maxPooling2d(temp, [2, 2], [2, 2]);\n    temp = DarknetConv2D_BN_Leaky(temp, 64, [3, 3]);\n    temp = maxPooling2d(temp, [2, 2], [2, 2]);\n    temp = DarknetConv2D_BN_Leaky(temp, 128, [3, 3]);\n    temp = maxPooling2d(temp, [2, 2], [2, 2]);\n    temp = DarknetConv2D_BN_Leaky(temp, 256, [3, 3]);\n    var x1 = temp;\n    temp = maxPooling2d(temp, [2, 2], [2, 2]);\n    temp = DarknetConv2D_BN_Leaky(temp, 512, [3, 3]);\n    temp = maxPooling2d(temp, [2, 2], [1, 1]);\n    temp = DarknetConv2D_BN_Leaky(temp, 1024, [3, 3]);\n    return tf.model({\n        inputs: inputs,\n        outputs: [x1, temp],\n        name: name\n    });\n}\nfunction YoloConvTiny(filters, x_in, name) {\n    if (name === void 0) { name = ''; }\n    var x;\n    var inputs;\n    if (Array.isArray(x_in)) {\n        inputs = [tf.layers.input({\n                shape: x_in[0].shape.slice(1)\n            }), tf.layers.input({\n                shape: x_in[1].shape.slice(1)\n            })];\n        x = inputs[0];\n        var x_skip = inputs[1];\n        x = DarknetConv2D_BN_Leaky(x, filters, [1, 1]);\n        x = tf.layers.upSampling2d({\n            size: [2, 2]\n        }).apply(x);\n        x = tf.layers.concatenate().apply([x, x_skip]);\n    }\n    else {\n        x = tf.layers.input({\n            shape: x_in.shape.slice(1)\n        });\n        inputs = x;\n        x = DarknetConv2D_BN_Leaky(x, filters, [1, 1]);\n    }\n    return tf.model({\n        inputs: inputs,\n        outputs: x,\n        name: name\n    }).apply(x_in);\n}\nfunction YoloOutput(x_in, filters, anchors, numClasses, name) {\n    if (name === void 0) { name = ''; }\n    var x = tf.layers.input({\n        shape: x_in.shape.slice(1)\n    });\n    var inputs = x;\n    x = DarknetConv2D_BN_Leaky(x, filters * 2, [3, 3]);\n    x = DarknetConv2D(x, anchors * (numClasses + 5), [1, 1]);\n    x = tf.layers.reshape({\n        targetShape: [x.shape[1], x.shape[2], anchors, numClasses + 5]\n    }).apply(x);\n    return tf.model({\n        inputs: inputs,\n        outputs: x,\n        name: name\n    });\n}\nfunction tinyYoloBody(imageInput, anchors, numClasses) {\n    var _a = DarknetTiny('yolo_darknet').apply(imageInput), x_8 = _a[0], x = _a[1];\n    x = YoloConvTiny(256, x, 'yolo_conv_0');\n    var output_0 = YoloOutput(x, 256, anchors, numClasses, 'yolo_output_0').apply(x);\n    x = YoloConvTiny(128, [x, x_8], 'yolo_conv_1');\n    var output_1 = YoloOutput(x, 128, anchors, numClasses, 'yolo_output_1').apply(x);\n    return tf.model({\n        inputs: imageInput,\n        outputs: [output_0, output_1]\n    });\n}\nexports.tinyYoloBody = tinyYoloBody;\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./src/model-utils/model.ts?");

/***/ }),

/***/ "./src/model-utils/utils.ts":
/*!**********************************!*\
  !*** ./src/model-utils/utils.ts ***!
  \**********************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.broadcastTo = exports.getCustom = exports.sparseCategoricalCrossentropy = exports.sigmoidCrossEntropyWithLogits = exports.booleanMask = void 0;\nvar tf = __importStar(__webpack_require__(/*! @tensorflow/tfjs-node */ \"@tensorflow/tfjs-node\"));\nfunction whereImpl(condShape, condVals) {\n    var indices = [];\n    for (var i = 0; i < condVals.length; i++) {\n        if (condVals[i]) {\n            indices.push(i);\n        }\n    }\n    var inBuffer = tf.buffer(condShape, 'int32');\n    var out = tf.buffer([indices.length, condShape.length], 'int32');\n    for (var i = 0; i < indices.length; i++) {\n        var loc = inBuffer.indexToLoc(indices[i]);\n        var offset = i * condShape.length;\n        out.values.set(loc, offset);\n    }\n    return out.toTensor();\n}\nfunction where(condition) {\n    var vals = condition.dataSync();\n    var res = whereImpl(condition.shape, vals);\n    return res;\n}\nfunction booleanMask(tensor, mask, axis) {\n    var $tensor = tensor;\n    var $mask = mask;\n    var axisFrom = axis == null ? 0 : axis;\n    var maskDim = $mask.rank;\n    var tensorShape = $tensor.shape;\n    var leadingSize = 1;\n    for (var i = axisFrom; i < axisFrom + maskDim; i++) {\n        leadingSize *= tensorShape[i];\n    }\n    var targetTensorShape = tensorShape.slice(0, axisFrom)\n        .concat([leadingSize], tensorShape.slice(axisFrom + maskDim));\n    var reshapedTensor = tf.reshape($tensor, targetTensorShape);\n    var reshapedMask = tf.reshape($mask, [-1]);\n    var positivePositions = where(reshapedMask);\n    var indices = tf.squeeze(positivePositions, [1]);\n    var res = tf.gather(reshapedTensor, indices, axisFrom);\n    // Ensure no memory leak.\n    if (tensor !== $tensor) {\n        $tensor.dispose();\n    }\n    if (mask !== $mask) {\n        $mask.dispose();\n    }\n    indices.dispose();\n    reshapedTensor.dispose();\n    reshapedMask.dispose();\n    positivePositions.dispose();\n    return res;\n}\nexports.booleanMask = booleanMask;\nfunction sigmoidCrossEntropyWithLogits(labels, logits) {\n    var $labels = labels;\n    var $logits = logits;\n    var maxOutput = tf.relu($logits);\n    var outputXTarget = tf.mul($logits, $labels);\n    var sigmoidOutput = tf.log1p(tf.exp(tf.neg(tf.abs($logits))));\n    return tf.add(tf.sub(maxOutput, outputXTarget), sigmoidOutput);\n}\nexports.sigmoidCrossEntropyWithLogits = sigmoidCrossEntropyWithLogits;\nfunction sparseCategoricalCrossentropy(target, output) {\n    var flatTarget = tf.floor(tf.reshape(target, [-1])).toInt();\n    output = tf.clipByValue(output, tf.backend().epsilon(), 1 - tf.backend().epsilon());\n    var outputShape = output.shape;\n    var oneHotTarget;\n    if (outputShape[outputShape.length - 1] > 1) {\n        oneHotTarget =\n            tf.oneHot(flatTarget, outputShape[outputShape.length - 1])\n                .reshape(outputShape);\n    }\n    else {\n        oneHotTarget = flatTarget.reshape(outputShape);\n    }\n    return tf.metrics.categoricalCrossentropy(oneHotTarget, output);\n}\nexports.sparseCategoricalCrossentropy = sparseCategoricalCrossentropy;\nfunction getCustom(reps) {\n    var customTile = tf.customGrad(function (x, save) {\n        save([x]);\n        return {\n            value: tf.tile(x, reps),\n            gradFunc: function (dy, saved) {\n                var x = saved[0];\n                var derX = function () {\n                    var xGrad = tf.zerosLike(x);\n                    if (x.rank === 1) {\n                        for (var i = 0; i < reps[0]; ++i) {\n                            xGrad = tf.add(xGrad, tf.slice(dy, [i * x.shape[0]], [x.shape[0]]));\n                        }\n                    }\n                    else if (x.rank === 2) {\n                        for (var i = 0; i < reps[0]; ++i) {\n                            for (var j = 0; j < reps[1]; ++j) {\n                                xGrad = tf.add(xGrad, tf.slice(dy, [i * x.shape[0], j * x.shape[1]], [\n                                    x.shape[0], x.shape[1]\n                                ]));\n                            }\n                        }\n                    }\n                    else if (x.rank === 3) {\n                        for (var i = 0; i < reps[0]; ++i) {\n                            for (var j = 0; j < reps[1]; ++j) {\n                                for (var k = 0; k < reps[2]; ++k) {\n                                    xGrad =\n                                        tf.add(xGrad, tf.slice(dy, [i * x.shape[0], j * x.shape[1], k * x.shape[2]], [x.shape[0], x.shape[1], x.shape[2]]));\n                                }\n                            }\n                        }\n                    }\n                    else if (x.rank === 4) {\n                        for (var i = 0; i < reps[0]; ++i) {\n                            for (var j = 0; j < reps[1]; ++j) {\n                                for (var k = 0; k < reps[2]; ++k) {\n                                    for (var l = 0; l < reps[3]; ++l) {\n                                        xGrad =\n                                            tf.add(xGrad, tf.slice(dy, [\n                                                i * x.shape[0], j * x.shape[1], k * x.shape[2],\n                                                l * x.shape[3]\n                                            ], [x.shape[0], x.shape[1], x.shape[2], x.shape[3]]));\n                                    }\n                                }\n                            }\n                        }\n                    }\n                    else if (x.rank === 5) {\n                        for (var i = 0; i < reps[0]; ++i) {\n                            for (var j = 0; j < reps[1]; ++j) {\n                                for (var k = 0; k < reps[2]; ++k) {\n                                    for (var l = 0; l < reps[3]; ++l) {\n                                        for (var m = 0; m < reps[4]; ++m) {\n                                            xGrad =\n                                                tf.add(xGrad, tf.slice(dy, [\n                                                    i * x.shape[0], j * x.shape[1], k * x.shape[2],\n                                                    l * x.shape[3], m * x.shape[4]\n                                                ], [x.shape[0], x.shape[1], x.shape[2], x.shape[3], x.shape[4]]));\n                                        }\n                                    }\n                                }\n                            }\n                        }\n                    }\n                    else {\n                        throw new Error(\"Gradient for tile operation is not implemented for rank-\" +\n                            (x.rank + \" tensors yet.\"));\n                    }\n                    return xGrad;\n                };\n                return derX();\n            }\n        };\n    });\n    return customTile;\n}\nexports.getCustom = getCustom;\nfunction broadcastTo(x, shape) {\n    var input = x;\n    var xShape = input.shape;\n    if (shape.length > input.rank) {\n        var newShape = input.shape.slice();\n        while (newShape.length < shape.length) {\n            newShape.unshift(1);\n        }\n        input = tf.reshape(input, newShape);\n    }\n    var inputShape = input.shape;\n    var reps = Array.from(shape);\n    for (var i = shape.length - 1; i >= 0; i--) {\n        if (inputShape[i] === shape[i]) {\n            reps[i] = 1;\n        }\n        else if (input.shape[i] !== 1) {\n            throw new Error(\"broadcastTo(): [\" + xShape + \"] cannot be broadcast to [\" + shape + \"].\");\n        }\n    }\n    var axes = reps.map(function (n, i) { return n > 1 ? i : -1; }).filter(function (i) { return i >= 0; });\n    if (axes.length === 0) {\n        return tf.clone(input);\n    }\n    return getCustom(reps)(input);\n}\nexports.broadcastTo = broadcastTo;\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./src/model-utils/utils.ts?");

/***/ }),

/***/ "./src/model.ts":
/*!**********************!*\
  !*** ./src/model.ts ***!
  \**********************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.predict = exports.train = void 0;\nvar tf = __importStar(__webpack_require__(/*! @tensorflow/tfjs-node */ \"@tensorflow/tfjs-node\"));\nvar path = __importStar(__webpack_require__(/*! path */ \"path\"));\nvar fs = __importStar(__webpack_require__(/*! fs-extra */ \"./node_modules/_fs-extra@8.1.0@fs-extra/lib/index.js\"));\nvar model_1 = __webpack_require__(/*! ./model-utils/model */ \"./src/model-utils/model.ts\");\nvar loss_1 = __webpack_require__(/*! ./model-utils/loss */ \"./src/model-utils/loss.ts\");\nvar dataset_1 = __webpack_require__(/*! ./model-utils/dataset */ \"./src/model-utils/dataset.ts\");\nfunction getAnchors() {\n    return tf.tensor([[10, 14], [23, 27], [37, 58], [81, 82], [135, 169], [344, 319]], [6, 2], 'float32');\n}\nfunction transformBBox(bboxes, width, height, labelIds) {\n    bboxes.forEach(function (box, index2) {\n        box[2] = box[0] + box[2];\n        box[3] = box[1] + box[3];\n        box[0] = box[0] / width;\n        box[1] = box[1] / height;\n        box[2] = box[2] / width;\n        box[3] = box[3] / height;\n        box[4] = labelIds[index2];\n    });\n    bboxes = bboxes.slice(0, 16);\n    if (bboxes.length < 16) {\n        bboxes = bboxes.concat(new Array(16 - bboxes.length).fill([0, 0, 0, 0, 0]));\n    }\n    return bboxes;\n}\nfunction createTinyModel(inputShape, anchors, numClasses, freezeBody) {\n    var imageInput = tf.input({\n        shape: [inputShape[0], inputShape[1], 3]\n    });\n    var modelBody = model_1.tinyYoloBody(imageInput, 3, numClasses);\n    return modelBody;\n}\nfunction checkTrainDatasetPool(datasetPool) {\n    var _a, _b;\n    return __awaiter(this, void 0, void 0, function () {\n        var meta;\n        return __generator(this, function (_c) {\n            switch (_c.label) {\n                case 0: return [4 /*yield*/, datasetPool.getDatasetMeta()];\n                case 1:\n                    meta = _c.sent();\n                    if (!meta) {\n                        throw new TypeError('DatasetMeta cannot be null.');\n                    }\n                    if (!datasetPool.train) {\n                        throw new TypeError('Train dataset cannot be null.');\n                    }\n                    if (!datasetPool.test) {\n                        throw new TypeError('Test dataset cannot be null.');\n                    }\n                    if (!((_a = meta === null || meta === void 0 ? void 0 : meta.size) === null || _a === void 0 ? void 0 : _a.train)) {\n                        throw new TypeError('The size of train dataset is unknown.');\n                    }\n                    if (!((_b = meta === null || meta === void 0 ? void 0 : meta.size) === null || _b === void 0 ? void 0 : _b.test)) {\n                        throw new TypeError('The size of test dataset is unknown.');\n                    }\n                    return [2 /*return*/, datasetPool];\n            }\n        });\n    });\n}\nvar train = function (api, options, context) { return __awaiter(void 0, void 0, void 0, function () {\n    function makeIterator() {\n        var _this = this;\n        var iterator = {\n            next: function () { return __awaiter(_this, void 0, void 0, function () {\n                var data;\n                return __generator(this, function (_a) {\n                    switch (_a.label) {\n                        case 0: return [4 /*yield*/, dataset.train.next()];\n                        case 1:\n                            data = _a.sent();\n                            if (!!data) return [3 /*break*/, 4];\n                            return [4 /*yield*/, dataset.train.seek(0)];\n                        case 2:\n                            _a.sent();\n                            return [4 /*yield*/, dataset.train.next()];\n                        case 3:\n                            data = _a.sent();\n                            if (!data) {\n                                throw new TypeError('Read sample error.');\n                            }\n                            _a.label = 4;\n                        case 4: return [2 /*return*/, tf.tidy(function () {\n                                var bboxes = data.label.map(function (ele2) { return ele2.bbox; });\n                                var labels = data.label.map(function (ele2) { var _a; return (_a = meta.categories) === null || _a === void 0 ? void 0 : _a.indexOf(ele2.name); });\n                                var transedBboxes = transformBBox(bboxes, meta.dimension.x, meta.dimension.y, labels);\n                                var ys = tf.tensor(transedBboxes);\n                                return {\n                                    value: {\n                                        xs: data === null || data === void 0 ? void 0 : data.data.tensor,\n                                        ys: ys\n                                    },\n                                    done: false\n                                };\n                            })];\n                    }\n                });\n            }); }\n        };\n        return iterator;\n    }\n    var modelDir, _a, epochs, _b, batchSize, _c, patience, dataset, meta, trainSize, batchesPerEpoch, numClasses, anchors, freezeBody, inputShape, model, loss, ds;\n    var _d;\n    return __generator(this, function (_e) {\n        switch (_e.label) {\n            case 0:\n                modelDir = context.workspace.modelDir;\n                _a = options.epochs, epochs = _a === void 0 ? 20 : _a, _b = options.batchSize, batchSize = _b === void 0 ? 16 : _b, _c = options.patience, patience = _c === void 0 ? 10 : _c;\n                return [4 /*yield*/, checkTrainDatasetPool(api.dataset)];\n            case 1:\n                dataset = _e.sent();\n                return [4 /*yield*/, dataset.getDatasetMeta()];\n            case 2:\n                meta = _e.sent();\n                if (!meta) {\n                    throw new TypeError('DatasetMeta cannot be null.');\n                }\n                if (!dataset.train) {\n                    throw new TypeError('Train dataset cannot be null.');\n                }\n                if (!((_d = meta === null || meta === void 0 ? void 0 : meta.size) === null || _d === void 0 ? void 0 : _d.train)) {\n                    throw new TypeError('The size of train dataset is unknown.');\n                }\n                if (!Array.isArray(meta.categories) || meta.categories.length === 0) {\n                    throw new TypeError('Categories is invalid.');\n                }\n                trainSize = meta.size.train;\n                batchesPerEpoch = Math.floor(trainSize / batchSize);\n                numClasses = meta.categories.length;\n                anchors = getAnchors();\n                freezeBody = true;\n                inputShape = [416, 416];\n                model = createTinyModel(inputShape, anchors, numClasses, freezeBody);\n                loss = [\n                    loss_1.lossWrap(model_1.getConstants().yolo_tiny_anchors1, numClasses),\n                    loss_1.lossWrap(model_1.getConstants().yolo_tiny_anchors2, numClasses)\n                ];\n                model.compile({\n                    optimizer: tf.train.rmsprop(1e-3),\n                    loss: loss\n                });\n                ds = tf.data.generator(makeIterator).batch(batchSize).mapAsync(function (data) { return __awaiter(void 0, void 0, void 0, function () {\n                    var ys;\n                    return __generator(this, function (_a) {\n                        switch (_a.label) {\n                            case 0: return [4 /*yield*/, dataset_1.transformTargets(data.ys, model_1.getConstants().yolo_tiny_anchors, 416)];\n                            case 1:\n                                ys = _a.sent();\n                                return [2 /*return*/, {\n                                        xs: data.xs,\n                                        ys: ys\n                                    }];\n                        }\n                    });\n                }); });\n                return [4 /*yield*/, model.fitDataset(ds, {\n                        batchesPerEpoch: batchesPerEpoch,\n                        epochs: epochs,\n                        callbacks: [\n                            tf.callbacks.earlyStopping({ monitor: 'loss', patience: parseInt(patience, 10), verbose: 1 }),\n                            tf.node.tensorBoard(modelDir + \"/tensorboard\")\n                        ]\n                    })];\n            case 3:\n                _e.sent();\n                return [4 /*yield*/, model.save(\"file://\" + modelDir)];\n            case 4:\n                _e.sent();\n                return [4 /*yield*/, fs.writeJSON(path.join(modelDir, 'categories.json'), meta.categories)];\n            case 5:\n                _e.sent();\n                return [2 /*return*/];\n        }\n    });\n}); };\nexports.train = train;\nvar predictModel;\nvar categories;\nvar predict = function (api, _, context) { return __awaiter(void 0, void 0, void 0, function () {\n    var modelDir, dataBatch, meta, tensors, result, _a, output_0, output_1, box0, box1, finalResult, _loop_1, i;\n    var _b, _c;\n    return __generator(this, function (_d) {\n        switch (_d.label) {\n            case 0:\n                modelDir = context.workspace.modelDir;\n                if (!!categories) return [3 /*break*/, 2];\n                return [4 /*yield*/, fs.readJSON(path.join(modelDir, 'categories.json'))];\n            case 1:\n                categories = _d.sent();\n                _d.label = 2;\n            case 2:\n                if (!!predictModel) return [3 /*break*/, 4];\n                return [4 /*yield*/, tf.loadLayersModel(\"file://\" + path.join(modelDir, 'model.json'))];\n            case 3:\n                predictModel = _d.sent();\n                _d.label = 4;\n            case 4: return [4 /*yield*/, ((_b = api.dataset.predicted) === null || _b === void 0 ? void 0 : _b.seek(0))];\n            case 5:\n                _d.sent();\n                return [4 /*yield*/, ((_c = api.dataset.predicted) === null || _c === void 0 ? void 0 : _c.nextBatch(-1))];\n            case 6:\n                dataBatch = _d.sent();\n                return [4 /*yield*/, api.dataset.getDatasetMeta()];\n            case 7:\n                meta = _d.sent();\n                if (!dataBatch) {\n                    throw new TypeError('No data found in dataset.');\n                }\n                tensors = tf.stack(dataBatch.map(function (ele) { return ele.data.tensor; }));\n                result = predictModel.predict(tensors);\n                _a = result, output_0 = _a[0], output_1 = _a[1];\n                box0 = loss_1.yolo_boxes(output_0, model_1.getConstants().yolo_tiny_anchors1, categories.length);\n                box1 = loss_1.yolo_boxes(output_1, model_1.getConstants().yolo_tiny_anchors2, categories.length);\n                finalResult = [];\n                _loop_1 = function (i) {\n                    var curbox0 = box0.slice(0, 3).map(function (box) { return tf.slice(box, [i], [1]); });\n                    var curbox1 = box1.slice(0, 3).map(function (box) { return tf.slice(box, [i], [1]); });\n                    var outputs = loss_1.yolo_nms([curbox0, curbox1]);\n                    var boxes = outputs.boxes, scores = outputs.scores, classes = outputs.classes, valid_detections = outputs.valid_detections;\n                    var predictResult = [];\n                    for (var i_1 = 0; i_1 < valid_detections; i_1++) {\n                        var boxArr = Array.from(tf.reshape(tf.slice(boxes, [0, i_1], [1, 1]), [4]).dataSync());\n                        var scoresArr = tf.reshape(tf.slice(scores, [0, i_1], [1, 1]), [1]).dataSync();\n                        var x = meta === null || meta === void 0 ? void 0 : meta.dimension.x;\n                        var y = meta === null || meta === void 0 ? void 0 : meta.dimension.y;\n                        var ratioX = dataBatch[0].data.originSize.width / x;\n                        var ratioY = dataBatch[0].data.originSize.height / y;\n                        var box = [\n                            boxArr[0] * x * ratioX,\n                            boxArr[1] * y * ratioY,\n                            (boxArr[2] - boxArr[0]) * x * ratioX,\n                            (boxArr[3] - boxArr[1]) * y * ratioY\n                        ];\n                        var id = tf.reshape(tf.slice(classes, [0, i_1], [1, 1]), [1]).dataSync()[0];\n                        predictResult.push({\n                            id: id,\n                            category: categories[id],\n                            score: scoresArr[0],\n                            box: box\n                        });\n                    }\n                    finalResult.push(predictResult);\n                };\n                for (i = 0; i < output_0.shape[0]; i++) {\n                    _loop_1(i);\n                }\n                return [2 /*return*/, finalResult];\n        }\n    });\n}); };\nexports.predict = predict;\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./src/model.ts?");

/***/ }),

/***/ "./node_modules/_universalify@0.1.2@universalify/index.js":
/*!****************************************************************!*\
  !*** ./node_modules/_universalify@0.1.2@universalify/index.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nexports.fromCallback = function (fn) {\n  return Object.defineProperty(function () {\n    if (typeof arguments[arguments.length - 1] === 'function') fn.apply(this, arguments)\n    else {\n      return new Promise((resolve, reject) => {\n        arguments[arguments.length] = (err, res) => {\n          if (err) return reject(err)\n          resolve(res)\n        }\n        arguments.length++\n        fn.apply(this, arguments)\n      })\n    }\n  }, 'name', { value: fn.name })\n}\n\nexports.fromPromise = function (fn) {\n  return Object.defineProperty(function () {\n    const cb = arguments[arguments.length - 1]\n    if (typeof cb !== 'function') return fn.apply(this, arguments)\n    else fn.apply(this, arguments).then(r => cb(null, r), cb)\n  }, 'name', { value: fn.name })\n}\n\n\n//# sourceURL=webpack://@pipcook/plugins-tfjs-yolo/./node_modules/_universalify@0.1.2@universalify/index.js?");

/***/ }),

/***/ "@tensorflow/tfjs-node":
/*!****************************************!*\
  !*** external "@tensorflow/tfjs-node" ***!
  \****************************************/
/***/ ((module) => {

"use strict";
module.exports = require("@tensorflow/tfjs-node");

/***/ }),

/***/ "assert":
/*!*************************!*\
  !*** external "assert" ***!
  \*************************/
/***/ ((module) => {

"use strict";
module.exports = require("assert");

/***/ }),

/***/ "constants":
/*!****************************!*\
  !*** external "constants" ***!
  \****************************/
/***/ ((module) => {

"use strict";
module.exports = require("constants");

/***/ }),

/***/ "fs":
/*!*********************!*\
  !*** external "fs" ***!
  \*********************/
/***/ ((module) => {

"use strict";
module.exports = require("fs");

/***/ }),

/***/ "os":
/*!*********************!*\
  !*** external "os" ***!
  \*********************/
/***/ ((module) => {

"use strict";
module.exports = require("os");

/***/ }),

/***/ "path":
/*!***********************!*\
  !*** external "path" ***!
  \***********************/
/***/ ((module) => {

"use strict";
module.exports = require("path");

/***/ }),

/***/ "stream":
/*!*************************!*\
  !*** external "stream" ***!
  \*************************/
/***/ ((module) => {

"use strict";
module.exports = require("stream");

/***/ }),

/***/ "util":
/*!***********************!*\
  !*** external "util" ***!
  \***********************/
/***/ ((module) => {

"use strict";
module.exports = require("util");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			// no module.id needed
/******/ 			// no module.loaded needed
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module is referenced by other modules so it can't be inlined
/******/ 	var __webpack_exports__ = __webpack_require__("./src/model.ts");
/******/ 	
/******/ 	return __webpack_exports__;
/******/ })()
;
});